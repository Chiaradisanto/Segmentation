{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chiaradisanto/Segmentation/blob/main/Copia_di_FinalCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **Save DICOM FILES as .png images**\n",
        "\n"
      ],
      "metadata": {
        "id": "gMO0iN8GRKKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Drive"
      ],
      "metadata": {
        "id": "JUgC825tO0b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "uKsop_XQpCzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Importing libraries\n"
      ],
      "metadata": {
        "id": "-KVe8M0YPNa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data analysis and manipulation\n",
        "import os #operating systems\n",
        "import scipy # multidimensional image processing\n",
        "from matplotlib import pyplot as plt # plot visualization\n",
        "from  scipy import ndimage\n",
        "\n"
      ],
      "metadata": {
        "id": "5yGhk8jGPMz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing and importing module for reading and writing DICOM files"
      ],
      "metadata": {
        "id": "E5vxApOCPtEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom\n",
        "import pydicom\n",
        "from pydicom import dcmread\n"
      ],
      "metadata": {
        "id": "2kM9yTPaPbCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**get_names** function takes as input the path of the selected subject containing the DICOM files \n",
        "\n"
      ],
      "metadata": {
        "id": "MrYANsJNP8Ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_names(path):\n",
        "    names = []\n",
        "    for root, dirnames, filenames in os.walk(path):\n",
        "        for filename in filenames:\n",
        "            _, ext = os.path.splitext(filename)\n",
        "            if ext in ['.dcm']:\n",
        "                names.append(filename)\n",
        "    return names"
      ],
      "metadata": {
        "id": "oDY57BbgP0ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DICOM files are ordered with sort function. "
      ],
      "metadata": {
        "id": "kPBY1sH3ZVk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = sorted(get_names(path)) # path of the .dicom files"
      ],
      "metadata": {
        "id": "ejgkxuCyQh4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A list containig all the DICOM files is created. \n",
        "This operation loads all DICOM files from the folder into a list for manipulation."
      ],
      "metadata": {
        "id": "LXr8DJRdZmUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = []\n",
        "for x in names:\n",
        "        files.append(pydicom.dcmread(path+'/'+x))\n",
        "len(files)\n"
      ],
      "metadata": {
        "id": "MNzkC2keQi54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that all the files contains SliceLocation in it. Otherwhise skip them\n",
        "\n"
      ],
      "metadata": {
        "id": "uNc1GT95e3ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slices = []\n",
        "skipcount = 0\n",
        "for f in files:\n",
        "    if hasattr(f, 'SliceLocation'):\n",
        "        slices.append(f)\n",
        "    else:\n",
        "        skipcount = skipcount + 1\n",
        "\n",
        "print(\"skipped, no SliceLocation: {}\".format(skipcount))"
      ],
      "metadata": {
        "id": "NzYvHGsEQqTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slices are sorted according to SliceLocation"
      ],
      "metadata": {
        "id": "BfKGH68zdmhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slices = sorted(slices, key=lambda s: s.SliceLocation, reverse=True)  #reverse is True to sort in descending order\n"
      ],
      "metadata": {
        "id": "A8fccvymQvG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The voxel values in the images are raw. \n",
        "\n",
        "**dicom_HU** converts raw values into Houndsfeld units.\n",
        "This function takes as input all the slices of the considered subject.\n",
        "The transformation is linear. \n",
        "\n",
        "Both the rescale intercept and rescale slope are stored in the DICOM headers at the time of image acquisition.\n",
        "The final value is rescaled to HU.\n",
        "Windowing is then applied in order to adjust the grayscale level of the images.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wmbn9H5nb5Hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dicom_HU(scan):\n",
        "    image = np.stack([s.pixel_array*s.RescaleSlope+s.RescaleIntercept for s in scan],axis=2).astype(np.int16) \n",
        "\n",
        "    img_min = 120 - 120 // 2 #minimum HU level\n",
        "    img_max = 120 + 120 // 2 #maximum HU level\n",
        "    window_image = image.copy()\n",
        "\n",
        "    window_image[window_image < img_min] = img_min #set img_min for all HU levels less than minimum HU level\n",
        "    window_image[window_image > img_max] = img_max #set img_max for all HU levels higher than maximum HU level\n",
        "    plt.figure(figsize=(20, 10))\n",
        "  \n",
        "    plt.style.use('grayscale') \n",
        "    plt.imshow(window_image[:,:,0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    return  np.array(window_image)"
      ],
      "metadata": {
        "id": "Lf6iW_JeQ4vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save as images in .png format in a specific folder. A folder for each patient is created."
      ],
      "metadata": {
        "id": "99PJxyGNlKZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_slices=len(files)\n",
        "for i in range(1,num_slices):\n",
        "    scan=dicom_HU(slices[i-1:i])\n",
        "    plt.axis('off')\n",
        "    plt.savefig(f\"{images_path}\"+str(i)+\".png\", bbox_inches='tight',pad_inches = 0,dpi=300, quality=95) #dpi represents the resolution in dots per inch.\n",
        "                                                                                                        # A high value results in a high resolution image.\n",
        "                                                                                                    \n",
        "                                                                                                        #quality represents the image quality\n",
        "                                                                                                        #on a scale from 1 (worst) to 95 (best)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YSn_n5l-RD5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These operations must be repeated for all the subjects changing the paths."
      ],
      "metadata": {
        "id": "dKqoj5faonaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save **ROI.nrrd** files as png. masks"
      ],
      "metadata": {
        "id": "u-yjWLVTQrgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Drive"
      ],
      "metadata": {
        "id": "J9mVDuENQ3z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "yJk-EOuE_dxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing SimpleITK to read .nrrd files "
      ],
      "metadata": {
        "id": "hkwpUx-0SjQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SimpleITK\n"
      ],
      "metadata": {
        "id": "YhqgPY5C_h5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries\n"
      ],
      "metadata": {
        "id": "vkFHKiorSiWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob #to find files\n",
        "import os\n",
        "import SimpleITK as sitk\n",
        "import nibabel as nib\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "awPxgjSo_lBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROI_path= glob.glob('/gdrive/MyDrive/ROI_out.nrrd') # Path of the .nrrd file\n"
      ],
      "metadata": {
        "id": "DQMiLlyo_mwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the .nrrd files"
      ],
      "metadata": {
        "id": "7_8MnZ4zUhlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask_sitk  = sitk.ReadImage(ROI_path[0]) #read the masks\n",
        "sitk_shape=mask_sitk.GetSize() #get the masks size\n",
        "print(sitk_shape) # the first 2 dimensions are height and width , the last dimension represents the number of masks in the folder"
      ],
      "metadata": {
        "id": "f_vOG_E3_qwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save as masks in .png format in a  specific folder.\n",
        "A folder for each subject is created.\n",
        "*images path* is the final folder to store the masks "
      ],
      "metadata": {
        "id": "HIYShr_lUek1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_slices=sitk_shape[2]\n",
        "for i in range(1,num_slices):\n",
        "    img=plt.imshow(sitk.GetArrayViewFromImage(mask_sitk)[i], cmap='gray')    \n",
        "    plt.axis('off')\n",
        "    plt.savefig(f\"{images_path}\"+str(i)+\".png\", bbox_inches='tight',pad_inches = 0,dpi=300, quality=95) #dpi represents the resolution in dots per inch.\n",
        "                                                                                                        # A high value results in a high resolution image.\n",
        "                                                                                                    \n",
        "                                                                                                        #quality represents the image quality\n",
        "                                                                                                        #on a scale from 1 (worst) to 95 (best)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "eAeXDFXT_vrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These operations must be repeated for all the subjects changing the paths."
      ],
      "metadata": {
        "id": "RcW_Ba2jU9eq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21 folders are created, one for each subject. At the end of these steps, each folder contains two subfolders \"images\" and \"masks\" with the associated images and masks for each subject.\n",
        "Subjects's folders are splitted in TRAINING and VALIDATION folders.\n",
        "18 subjects are in TRAINING folder while 3 subjects are in VALIDATION one.\n",
        "7-fold cross validation is then performed."
      ],
      "metadata": {
        "id": "dOySf4gqVE3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final folders creation"
      ],
      "metadata": {
        "id": "gYyYfujXcZWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the images and masks of each subject have been saved , in the next part of the code four folders have been created: 'train_images' and 'train_masks' in which are all the images and the associated masks of the training set, and 'validation_images' and 'validation_masks' which contains the images and the associated masks of the validation set. This operation is necessary to perform Data Augumentation in a correct way, described in the later steps of the code.\n",
        "The images and the associated masks are charaterized by the same name."
      ],
      "metadata": {
        "id": "31_9eKTVWkEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Drive"
      ],
      "metadata": {
        "id": "DcODJfJ6XRBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "bIEhk1CxWo6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "gyJKqGKvXWUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image \n",
        "import cv2 \n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from natsort import natsorted\n",
        "from google.colab.patches import cv2_imshow\n"
      ],
      "metadata": {
        "id": "oWgB7r57XZEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_path='/gdrive/MyDrive/TRAIN' #training path\n",
        "VALIDATION_path='/gdrive/MyDrive/VALIDATION'# validation path"
      ],
      "metadata": {
        "id": "8QS7UAElXd5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the images and masks of training set"
      ],
      "metadata": {
        "id": "_z3zLbzrZOyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_train_data(train_path):\n",
        "\n",
        "    train_x = (glob(f\"{TRAIN_path}/*/images/*.png\"))\n",
        "    train_y = (glob(f\"{TRAIN_path}/*/masks/*.png\"))\n",
        " \n",
        "    return train_x,train_y"
      ],
      "metadata": {
        "id": "blkI5cIyXhKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_x,train_y) = load_train_data(TRAIN_path)\n"
      ],
      "metadata": {
        "id": "FutlPVyqXmn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images and Masks of the training set are sorted naturally with natsorted function "
      ],
      "metadata": {
        "id": "A0N1jPpBZdTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x=natsorted(train_x)\n",
        "train_y=natsorted(train_y)\n",
        "print(len(train_x))   #train_x and train_y must have the same length , since they must contains the same number of files.\n",
        "print(len(train_y))"
      ],
      "metadata": {
        "id": "NU76pLQYZXiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the images and masks of validation set\n"
      ],
      "metadata": {
        "id": "DIcvIaESZQll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_val_data(val_path):\n",
        "    val_x= (glob(f\"{VALIDATION_path}/*/images/*.png\"))\n",
        "    val_y= (glob(f\"{VALIDATION_path}/*/masks/*.png\"))\n",
        "    return val_x,val_y"
      ],
      "metadata": {
        "id": "5OTQj2V7Xi5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(val_x,val_y) = load_val_data(VALIDATION_path)\n"
      ],
      "metadata": {
        "id": "vidWEbUAXpN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images and Masks of the validation set are sorted naturally with natsorted function.\n"
      ],
      "metadata": {
        "id": "rOS7UCKoaBWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_x=natsorted(val_x)\n",
        "val_y=natsorted(val_y)\n",
        "print(len(val_x))\n",
        "print(len(val_y))"
      ],
      "metadata": {
        "id": "oDEnAlgBZ_gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the 'train_images' and 'train_masks' folders"
      ],
      "metadata": {
        "id": "WR69pqhQo0Y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_train='/gdrive/MyDrive/train_images/images/' # final images path\n",
        "mask_path_train='/gdrive/MyDrive/train/train_masks/masks/' #final masks path"
      ],
      "metadata": {
        "id": "fPshTuOpafex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H = 256 #height \n",
        "W = 256 #width\n",
        "for idx, (x, y) in tqdm(enumerate(zip(train_x, train_y)), total=len(train_x)):\n",
        "        \"\"\" Extracting the folder name and image name for each subject \"\"\"\n",
        "        dir_name = x.split(\"/\")[-3]\n",
        "        name = dir_name + \"_\" + x.split(\"/\")[-1].split(\".\")[0] #extract the name of every subject's folder \n",
        "        \"\"\" Read the image and mask \"\"\"\n",
        "        x = cv2.imread(x, cv2.IMREAD_GRAYSCALE) #read the image\n",
        "        y = cv2.imread(y, cv2.IMREAD_GRAYSCALE) #read the mask\n",
        "        X = [x]\n",
        "        Y = [y]\n",
        "        idx = 0\n",
        "        for i, m in zip(X, Y):\n",
        "            i = cv2.resize(i, (W, H),interpolation = cv2.INTER_CUBIC)   #images are resized from 512x512 to 256x256 through bicubic interpolation\n",
        "            m = cv2.resize(m, (W, H),interpolation = cv2.INTER_CUBIC)   #masks are resized from 512x512 to 256x256 through bicubic interpolation\n",
        "\n",
        "            tmp_image_name = f\"{name}.png\"  #image and mask are saved with the same name \n",
        "            tmp_mask_name  = f\"{name}.png\" \n",
        "\n",
        "            image_path = os.path.join(image_path_train, tmp_image_name)\n",
        "            mask_path  = os.path.join(mask_path_train, tmp_mask_name)\n",
        "            print(tmp_image_name)\n",
        "\n",
        "            cv2.imwrite(image_path,i, [int(cv2.IMWRITE_PNG_COMPRESSION),0]) #save images in the folder\n",
        "            cv2.imwrite(mask_path, m, [int(cv2.IMWRITE_PNG_COMPRESSION),0]) #save masks in the folder\n",
        "                                                                            #with cv2.IMWRITE_PNG_COMPRESSION parameter the compression of the png image\n",
        "                                                                            #can be controlled. The value 0 pruduces the lowest compression\n",
        "            idx += 1"
      ],
      "metadata": {
        "id": "tSwt7yiTXsE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the 'validation_images' and 'validation_masks' folders"
      ],
      "metadata": {
        "id": "uq7rNv9ApAa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_validation='/gdrive/MyDrive/validation_images/images/' # final images path\n",
        "mask_path_validation='/gdrive/MyDrive/train/validation_masks/masks/' #final masks path"
      ],
      "metadata": {
        "id": "oFsVxit6pIXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H = 256 #height \n",
        "W = 256 #width\n",
        "for idx, (x, y) in tqdm(enumerate(zip(val_x, val_y)), total=len(val_x)):\n",
        "        \"\"\" Extracting the folder name and image name for each subject \"\"\"\n",
        "        dir_name = x.split(\"/\")[-3]\n",
        "        name = dir_name + \"_\" + x.split(\"/\")[-1].split(\".\")[0] #extract the name of every subject's folder \n",
        "        \"\"\" Read the image and mask \"\"\"\n",
        "        x = cv2.imread(x, cv2.IMREAD_GRAYSCALE) #read the image\n",
        "        y = cv2.imread(y, cv2.IMREAD_GRAYSCALE) #read the mask\n",
        "        X = [x]\n",
        "        Y = [y]\n",
        "        idx = 0\n",
        "        for i, m in zip(X, Y):\n",
        "            i = cv2.resize(i, (W, H),interpolation = cv2.INTER_CUBIC)   #images are resized from 512x512 to 256x256 through bicubic interpolation\n",
        "            m = cv2.resize(m, (W, H),interpolation = cv2.INTER_CUBIC)   #masks are resized from 512x512 to 256x256 through bicubic interpolation\n",
        "\n",
        "            tmp_image_name = f\"{name}.png\"  #image and mask are saved with the same name \n",
        "            tmp_mask_name  = f\"{name}.png\" \n",
        "\n",
        "            image_path = os.path.join(image_path_validation, tmp_image_name)\n",
        "            mask_path  = os.path.join(mask_path_validation, tmp_mask_name)\n",
        "            print(tmp_image_name)\n",
        "\n",
        "            cv2.imwrite(image_path,i, [int(cv2.IMWRITE_PNG_COMPRESSION),0]) #save images in the folder\n",
        "            cv2.imwrite(mask_path, m, [int(cv2.IMWRITE_PNG_COMPRESSION),0]) #save masks in the folder\n",
        "                                                                            #with cv2.IMWRITE_PNG_COMPRESSION parameter the compression of the png image\n",
        "                                                                            #can be controlled. The value 0 pruduces the lowest compression\n",
        "            idx += 1"
      ],
      "metadata": {
        "id": "-vyJvwtXX0sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Baseline U-Net**"
      ],
      "metadata": {
        "id": "FGhUFCRLwWhb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Augmentation"
      ],
      "metadata": {
        "id": "cgDvMX7_psHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Drive"
      ],
      "metadata": {
        "id": "K6odPXqWqCrJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries\n"
      ],
      "metadata": {
        "id": "H1u1aAq1qE8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "H3uHM0WCML7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "jsVI_qZLqKdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Validation paths"
      ],
      "metadata": {
        "id": "R6FcnaoWzkmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_path = \"/gdrive/MyDrive/train_images\" # training images path\n",
        "train_mask_path = \"/gdrive/MyDrive/train_masks\" # training masks path\n",
        "\n",
        "val_img_path = \"/gdrive/MyDrive/validation_images\" # validation images path\n",
        "val_mask_path = \"/gdrive/MyDrive/validation_masks\" # validation masks path"
      ],
      "metadata": {
        "id": "K2y568h1qX5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation is applied simultaneously to trainining images and masks"
      ],
      "metadata": {
        "id": "yaZnhwhYxMrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_data_gen_args_train = dict(rescale=1./255,   #rescale the images\n",
        "                     rotation_range=90,          #random rotation \n",
        "                     brightness_range=[0.3,1.5], # random change of brightness\n",
        "                     width_shift_range=0.3,      # random width shifting\n",
        "                     height_shift_range=0.3,     #random height shifting\n",
        "                     shear_range=0.5,            #shear transformation\n",
        "                     horizontal_flip=True,       #horizontal flip\n",
        "                     vertical_flip=True,         # vertical flip\n",
        "                     fill_mode='reflect')        # fill mode\n",
        "\n",
        "mask_data_gen_args_train = dict(\n",
        "                     rotation_range=90,          #random rotation \n",
        "                     brightness_range=[0.3,1.5], # random change of brightness\n",
        "                     width_shift_range=0.3,      # random width shifting\n",
        "                     height_shift_range=0.3,     #random height shifting\n",
        "                     shear_range=0.5,            #shear transformation\n",
        "                     horizontal_flip=True,       #horizontal flip\n",
        "                     vertical_flip=True,         # vertical flip\n",
        "                     fill_mode='reflect',       # fill mode\n",
        "\n",
        "                     preprocessing_function = lambda x: np.where(x>0.5, 1, 0).astype(x.dtype) #Binarize the masks\n",
        "                     \n",
        "                     )  \n",
        "\n",
        "image_data_generator_train = ImageDataGenerator(**img_data_gen_args_train)\n",
        "mask_data_generator_train = ImageDataGenerator(**mask_data_gen_args_train)"
      ],
      "metadata": {
        "id": "qlCteBicqmU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation is not applied to validation set.\n",
        "ImageDataGenerator is used to rescale the images and binarize the masks only."
      ],
      "metadata": {
        "id": "Jz6dwulgxVtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_data_gen_args_val = dict(rescale=1./255) #rescale the images\n",
        "\n",
        "mask_data_gen_args_val = dict(\n",
        "                     preprocessing_function = lambda x: np.where(x>0.5, 1, 0).astype(x.dtype)\n",
        "                     \n",
        "                     ) #Binarize the masks. \n",
        "\n",
        "image_data_generator_val = ImageDataGenerator(**img_data_gen_args_val)\n",
        "mask_data_generator_val = ImageDataGenerator(**mask_data_gen_args_val)"
      ],
      "metadata": {
        "id": "fsHp5ybeq_NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Generators.\n",
        "The first generator is for training images and masks and the other one is for validation. These generators will be the input of the model."
      ],
      "metadata": {
        "id": "lecC32BL_5h2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed=42\n",
        "batch_size=16\n",
        "image_generator = image_data_generator_train.flow_from_directory(train_img_path, #path\n",
        "                                                           seed=seed, # must be the same to ensure that images and masks are edited in the same way\n",
        "                                                           batch_size=batch_size, #batch size\n",
        "                                                           color_mode = 'grayscale', # grayscale. Channel number is equal to 1\n",
        "                                                           target_size=(256,256), # height and the width\n",
        "                                                           class_mode=None)  # Set this otherwise it returns multiple numpy arrays \n",
        "                                                                            \n",
        "\n",
        "mask_generator = mask_data_generator_train.flow_from_directory(train_mask_path, \n",
        "                                                         seed=seed, \n",
        "                                                         batch_size=batch_size,\n",
        "                                                         color_mode = 'grayscale',\n",
        "                                                         target_size=(256,256)  , \n",
        "                                                         class_mode=None)\n",
        "\n",
        "\n",
        "valid_img_generator = image_data_generator_val.flow_from_directory(val_img_path, \n",
        "                                                               seed=seed, \n",
        "                                                               batch_size=batch_size, \n",
        "                                                               color_mode = 'grayscale', \n",
        "                                                               target_size=(256,256),\n",
        "                                                               class_mode=None) \n",
        "\n",
        "\n",
        "valid_mask_generator = mask_data_generator_val.flow_from_directory(val_mask_path, \n",
        "                                                               seed=seed, \n",
        "                                                               batch_size=batch_size, \n",
        "                                                               target_size=(256,256),\n",
        "                                                               \n",
        "                                                               color_mode = 'grayscale',  \n",
        "                                                               class_mode=None)  \n",
        "\n",
        "\n",
        "train_generator = zip(image_generator, mask_generator) # zip function to concatenate image and mask generators\n",
        "val_generator = zip(valid_img_generator, valid_mask_generator)"
      ],
      "metadata": {
        "id": "LuqogoIwrVSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifying generators"
      ],
      "metadata": {
        "id": "73XdsLsK0i5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show some example of augmented images and check if they are associated in correct way to the masks"
      ],
      "metadata": {
        "id": "ZbUfnkT5AgL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x, y = train_generator.__next__()\n",
        "\n",
        "for i in range(0,8):\n",
        "    image = x[i,:,:,0]\n",
        "    mask= y[i,:,:,0]\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oG81217DraQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if images and masks are rescaled. \n",
        "Values must be between 0 and 1 for images and 0 or 1 for masks"
      ],
      "metadata": {
        "id": "DTF07IHW1F43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.max())\n",
        "print(y.max())"
      ],
      "metadata": {
        "id": "ICqWYfBgrc1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "u0Uu6kqV2m0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "xf_pDHW7nUnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model, load_model, save_model\n",
        "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate,UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "\n"
      ],
      "metadata": {
        "id": "TmjTAU-RnK2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the input shape of the model"
      ],
      "metadata": {
        "id": "JxutoNnl3UWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = x.shape[1]\n",
        "IMG_WIDTH  = x.shape[2]\n",
        "IMG_CHANNELS = x.shape[3]\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "print(input_shape)"
      ],
      "metadata": {
        "id": "2_BQXax23SO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline U-Net Architecture\n"
      ],
      "metadata": {
        "id": "lS-rEBOi3beV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(input_shape)\n",
        "#Contraction path\n",
        "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
        "c1= tf.keras.layers.BatchNormalization()(c1)\n",
        "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "c1= tf.keras.layers.BatchNormalization()(c1)\n",
        "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "c2= tf.keras.layers.BatchNormalization()(c2)\n",
        "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "c2= tf.keras.layers.BatchNormalization()(c2)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        " \n",
        "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "c3= tf.keras.layers.BatchNormalization()(c3)\n",
        "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
        "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "c3= tf.keras.layers.BatchNormalization()(c3)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        " \n",
        "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "c4= tf.keras.layers.BatchNormalization()(c4)\n",
        "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
        "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "c4= tf.keras.layers.BatchNormalization()(c4)\n",
        "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        " \n",
        "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "c5= tf.keras.layers.BatchNormalization()(c5)\n",
        "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
        "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "c5= tf.keras.layers.BatchNormalization()(c5)\n",
        "\n",
        "#Expansive path \n",
        "\n",
        "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        " \n",
        "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        " \n",
        "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        " \n",
        "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        " \n",
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)"
      ],
      "metadata": {
        "id": "7QVvEAC0sCIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "qdKklGHusEWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the steps per epoch for training and validation required to train the model"
      ],
      "metadata": {
        "id": "r9T_yeLO2jvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_imgs = len(os.listdir(\"/gdrive/MyDrive/train_images/images\")) #images path\n",
        "num_val_images = len(os.listdir(\"/gdrive/MyDrive/val_images/images\"))   #masks path\n",
        "\n",
        "steps_per_epoch = num_train_imgs//batch_size\n",
        "val_steps_per_epoch = num_val_images//batch_size\n"
      ],
      "metadata": {
        "id": "NCnavx46ryDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the model metrics and losses.\n",
        "Dice Loss, IoU Loss, Tversky Loss, Focal Loss have been tested"
      ],
      "metadata": {
        "id": "qjeCiyk34Rv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=0.0001): #smooth factor to avoid zero division\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "\n",
        "    return ((2. * intersection + smooth) / (K.sum(y_true_f) +\n",
        "            K.sum(y_pred_f) + smooth))\n",
        "\n",
        "\n",
        "def dice_coefficient_loss(y_true, y_pred):\n",
        "    return 1.0-dice_coefficient(y_true, y_pred)\n",
        "\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred))\n",
        "    sum_ = K.sum(K.square(y_true)) + K.sum(K.square(y_pred))\n",
        "    jac = (intersection) / (sum_ - intersection)\n",
        "    return jac\n",
        "\n",
        "def iou_loss(y_true, y_pred):\n",
        "    return 1-iou(y_true, y_pred)\n",
        "\n",
        "def tversky(y_true, y_pred):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
        "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
        "    alpha = 0.7 #different values could be set\n",
        "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    return 1 - tversky(y_true,y_pred)\n"
      ],
      "metadata": {
        "id": "KQOYs3R0sHRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python libraries for focal loss"
      ],
      "metadata": {
        "id": "r7SaQE2xoZ1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install focal-loss"
      ],
      "metadata": {
        "id": "QS2VaILKoTqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from focal_loss import BinaryFocalLoss"
      ],
      "metadata": {
        "id": "BqFhmDR_of6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Learning Rate and Optimizer"
      ],
      "metadata": {
        "id": "UoA9h-ph5csb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 5e-5\n",
        "optim = tf.keras.optimizers.Adam(LR) #Adaptive Moment Estimation Optimizer"
      ],
      "metadata": {
        "id": "E2DVmo2CsJYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Metrics used"
      ],
      "metadata": {
        "id": "nAkXeJUJ5uaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [iou, dice_coefficient, 'binary_accuracy','Recall','Precision']\n"
      ],
      "metadata": {
        "id": "4vjvTbkFsLIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model"
      ],
      "metadata": {
        "id": "FZRwY7J-5yEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dice loss is chosen as loss function"
      ],
      "metadata": {
        "id": "R6Bh7wp2o0Nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optim, loss=dice_coefficient_loss, metrics=metrics)\n"
      ],
      "metadata": {
        "id": "66jJCnt8sNLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add callback to save the best model.\n",
        "The best model has the highest dice coefficient on the validation set"
      ],
      "metadata": {
        "id": "OafE0_t16Qnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/gdrive/MyDrive/chk/',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_dice_coefficient',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "rCi4vh1c6OYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "prwjBXAU7Mdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_generator,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          epochs=70,\n",
        "          verbose=1,\n",
        "          callbacks=model_checkpoint_callback,\n",
        "          validation_data=val_generator,\n",
        "          validation_steps=val_steps_per_epoch)"
      ],
      "metadata": {
        "id": "IvFm8H7asPCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model in .h5 format for future use"
      ],
      "metadata": {
        "id": "lNEMYj0K6cq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path='/gdrive/MyDrive/model.h5'"
      ],
      "metadata": {
        "id": "BuYv7R0T6fr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(model_path)\n"
      ],
      "metadata": {
        "id": "WLp6SvwwsRo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on Validation Set"
      ],
      "metadata": {
        "id": "JUtSZ41j97XB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "ZevFWgGBEGZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from tensorflow.keras.metrics import MeanIoU, Recall, Precision, BinaryAccuracy\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "NyWyWZMbEF6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load previously saved model"
      ],
      "metadata": {
        "id": "kBYESabh-KYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(model_path,compile=False)"
      ],
      "metadata": {
        "id": "I0LzkvZL9-5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a, b = val_generator.__next__() # Evaluation is performed directly in batches \n"
      ],
      "metadata": {
        "id": "oyIJ5g-l-S0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction on random images of the validation set"
      ],
      "metadata": {
        "id": "2naIlB1jBId5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "test_img_number = random.randint(a.shape[0]) # random value from 0 to the number of images in the validation set\n",
        "test_img = a[test_img_number] #testing image\n",
        "ground_truth=b[test_img_number] # real mask\n",
        "test_img_input=np.expand_dims(test_img, 0)\n",
        "prediction = (model.predict(test_img_input)[0,:,:,0] > 0.5).astype(np.uint8) #prediction on testing image \n"
      ],
      "metadata": {
        "id": "a0tv3QQu-XPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show random examples\n"
      ],
      "metadata": {
        "id": "ZF89G_snBoRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing image, predicted mask and real mask can be displayed"
      ],
      "metadata": {
        "id": "4XKTl9sRBuYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(231)\n",
        "plt.axis('off')\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_img[:,:,0], cmap='gray')\n",
        "\n",
        "\n",
        "plt.subplot(232)\n",
        "plt.title('Real Mask ')\n",
        "plt.axis('off')\n",
        "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
        "plt.subplot(233)\n",
        "plt.axis('off')\n",
        "plt.title('Predicted mask')\n",
        "plt.imshow(prediction, cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BpcHyGk5BniE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the Mean Intersection Over Union metric from keras metrics"
      ],
      "metadata": {
        "id": "_iovmPhpCINN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import MeanIoU\n"
      ],
      "metadata": {
        "id": "zYAeKjE0Cm2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the MeanIoU for a single image\n"
      ],
      "metadata": {
        "id": "HmVc4sa1B7xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 2 # 2 classes for binary segmentation\n",
        "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "\n",
        "IOU_keras.update_state(ground_truth[:,:,0], prediction)\n",
        "print(\"Mean IoU =\", IOU_keras.result().numpy())"
      ],
      "metadata": {
        "id": "q4infJ20CkfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the MeanIoU of each image in the validation set.\n",
        "The MeanIoU for each image can be displayed and the final average value on all the predictions is computed"
      ],
      "metadata": {
        "id": "BJQzrFoyCxjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "IoU_values = []\n",
        "for img in range(a.shape[0]): \n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    temp_img_input=np.expand_dims(temp_img, 0)\n",
        "    prediction = (model.predict(temp_img_input)[0,:,:,0] > 0.5).astype(np.uint8)\n",
        "    \n",
        "    IoU = MeanIoU(num_classes=n_classes)\n",
        "    IoU.update_state(ground_truth[:,:,0], prediction)\n",
        "    IoU = IoU.result().numpy()\n",
        "    IoU_values.append(IoU)\n",
        "\n",
        "    print(IoU)\n",
        "    \n",
        "df = pd.DataFrame(IoU_values, columns=[\"IoU\"])\n",
        "df = df[df.IoU != 1.0]\n",
        "\n",
        "mean_IoU = df.mean().values\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean IoU is: \", mean_IoU)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "QUFL6OZoCwP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary Accuracy"
      ],
      "metadata": {
        "id": "cHili6yPCxmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BinaryAccuracy_values = []\n",
        "for img in range(a.shape[0]):\n",
        "      temp_img = a[img]\n",
        "      ground_truth=b[img]\n",
        "      temp_img_input=np.expand_dims(temp_img, 0)\n",
        "      prediction = (model.predict(temp_img_input)[0,:,:,0]> 0.5).astype(np.uint8)\n",
        "      Accuracy=BinaryAccuracy()\n",
        "      Accuracy.update_state(ground_truth[:,:,0], prediction)\n",
        "      Accuracy = Accuracy.result().numpy()\n",
        "      BinaryAccuracy_values.append(Accuracy)\n",
        "\n",
        "      print(Accuracy)\n",
        "      \n",
        "\n",
        "df = pd.DataFrame(BinaryAccuracy_values, columns=[\"BinaryAccuracy\"])\n",
        "df = df[df.BinaryAccuracy != 1.0]    \n",
        "mean_acc = df.mean().values\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "\n",
        "print(\"Mean Binary Accuracy is: \", mean_acc)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0IQUw8amCqf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision"
      ],
      "metadata": {
        "id": "jM4Uax7rDyMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Precision_values = []\n",
        "for img in range(a.shape[0]):\n",
        "\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    temp_img_input=np.expand_dims(temp_img, 0)\n",
        "    prediction = (model.predict(temp_img_input)[0,:,:,0]> 0.5).astype(np.uint8)\n",
        "    precision=precision_score(ground_truth[:,:,0], prediction, average='macro',zero_division=1) # to avoid zero division\n",
        "    Precision_values.append (precision)\n",
        "    print(precision)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(Precision_values, columns=[\"Precision\"])\n",
        "df = df[df.Precision != 1.0]    \n",
        "mean_precision = df.mean().values\n",
        "std=df.std()\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean Precision is: \", mean_precision)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)"
      ],
      "metadata": {
        "id": "KK_kB_X1CkKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall"
      ],
      "metadata": {
        "id": "X95Zt4-2Dwwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Recall_values = []\n",
        "for img in range(a.shape[0]):\n",
        "\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    temp_img_input=np.expand_dims(temp_img, 0)\n",
        "    prediction = (model.predict(temp_img_input)[0,:,:,0]> 0.5).astype(np.float32)\n",
        "    recall=recall_score(ground_truth[0,:,:,0], prediction, average='macro',zero_division=1) # to avoid zero division\n",
        "    Recall_values.append (recall)\n",
        "    print(recall)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(Recall_values, columns=[\"Recall\"])\n",
        "df = df[df.Recall != 1.0]    \n",
        "boxplot = df.boxplot(grid=False,vert=True,color='blue')\n",
        "mean_rec = df.mean().values\n",
        "std=df.std()\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean Recall is: \", mean_rec)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)"
      ],
      "metadata": {
        "id": "TWfJ9a6LDtOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on Test Set"
      ],
      "metadata": {
        "id": "knO6VbqFpnuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21 subjects are used to test the model performance. Images and masks of testing dataset were preprocessed in the same way of training and validation ones.\n",
        "21 folders were created each containing the images and the corresponding masks. "
      ],
      "metadata": {
        "id": "DQ3IB9LlrEWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Drive"
      ],
      "metadata": {
        "id": "rdI5R8FHp-7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/gdrive\")\n"
      ],
      "metadata": {
        "id": "VIwmM82up-jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "ubr-0lTAp7pH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from tensorflow.keras.metrics import MeanIoU, Recall, Precision, BinaryAccuracy, IoU\n"
      ],
      "metadata": {
        "id": "vbxVx9d7pqvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load previously saved model\n"
      ],
      "metadata": {
        "id": "VBGSE4ETqGfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path='/gdrive/MyDrive/model.h5'"
      ],
      "metadata": {
        "id": "ZiazIhWlqSPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_path, compile=False)"
      ],
      "metadata": {
        "id": "1mniEHcEqJLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Images and Masks paths"
      ],
      "metadata": {
        "id": "t3LT_UEiqoL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_path = \"/test_images/images\" #  images path\n",
        "test_mask_path = \"/test_masks/masks\"  #  masks path"
      ],
      "metadata": {
        "id": "duNIyo-Wqa_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ImageDataGenerator is used to rescale the images and binarize the masks."
      ],
      "metadata": {
        "id": "QEi_2_xnsH8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_data_gen_args_test = dict(rescale=1.0 / 255)\n",
        "\n",
        "mask_data_gen_args_test = dict(\n",
        "    preprocessing_function=lambda x: np.where(x > 0.5, 1, 0).astype(x.dtype)\n",
        ")  # Binarize the output again.\n",
        "\n",
        "image_data_generator_test = ImageDataGenerator(**img_data_gen_args_test)\n",
        "mask_data_generator_test = ImageDataGenerator(**mask_data_gen_args_test)"
      ],
      "metadata": {
        "id": "ymXduQXar0m-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ordering in correct way the images and the masks"
      ],
      "metadata": {
        "id": "Dg25sqxVsU1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_img_names(dir: str):\n",
        "    names = [os.path.join(dir, x) for x in os.listdir(dir)]\n",
        "    names = sorted(names, key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0]))\n",
        "    return names\n",
        "\n",
        "\n",
        "test_img_names = pd.DataFrame(sort_img_names(test_img_path), columns=[\"filename\"])\n",
        "test_mask_names = pd.DataFrame(sort_img_names(test_mask_path), columns=[\"filename\"])"
      ],
      "metadata": {
        "id": "8n75JJVcsNpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_of_images= len(test_img_names)\n",
        "print(n_of_images)"
      ],
      "metadata": {
        "id": "wyxxY4cnsyqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch size is equal to the number of images (and masks) in test set."
      ],
      "metadata": {
        "id": "nfi_6ksvtEc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size= n_of_images "
      ],
      "metadata": {
        "id": "HKoOPtjfsvN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "test_img_generator = image_data_generator_test.flow_from_dataframe(\n",
        "    test_img_names,\n",
        "    seed=seed,\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    shuffle=False, # to mantain the correct order of images and masks\n",
        "    target_size=(256, 256),\n",
        "    class_mode=None,\n",
        ") \n",
        "test_mask_generator = mask_data_generator_test.flow_from_dataframe(\n",
        "    test_mask_names,\n",
        "    seed=seed,\n",
        "    batch_size=batch_size,\n",
        "    target_size=(256, 256),\n",
        "    shuffle=False, #to mantain the correct order of images and masks\n",
        "    color_mode=\"grayscale\",  \n",
        "    class_mode=None,\n",
        ") \n",
        "\n",
        "\n",
        "test_generator = zip(valid_img_generator, valid_mask_generator)"
      ],
      "metadata": {
        "id": "-SBUQf0QsfaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a, b = test_generator.__next__()\n"
      ],
      "metadata": {
        "id": "JaHnBVi8tssv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction on random images of the test set"
      ],
      "metadata": {
        "id": "1OLO74sQuDQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  test_img_number = random.randint(a.shape[0]) #random number\n",
        "  test_img = a[test_img_number] #testing image\n",
        "  ground_truth=b[test_img_number] #real mask\n",
        "  test_img_input=np.expand_dims(test_img, 0) \n",
        "  prediction = (model.predict(test_img_input)[0,:,:,0] > 0.5 ).astype(np.uint8) #predicted mask\n",
        "  plt.figure(figsize=(16, 8))\n",
        "  plt.subplot(231)\n",
        "  plt.axis('off')\n",
        "  plt.title('Testing Image')\n",
        "  plt.imshow(test_img[:,:,0], cmap='gray')\n",
        "\n",
        "\n",
        "\n",
        "  plt.subplot(232)\n",
        "  plt.title('Real Mask ')\n",
        "  plt.axis('off')\n",
        "  plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
        "  plt.subplot(233)\n",
        "\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.title('Predicted mask')\n",
        "  plt.imshow(prediction, cmap='gray')\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "80BTTe8ZuFn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MeanIoU for a single image"
      ],
      "metadata": {
        "id": "H-Loc8nIuxI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 2\n",
        "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "IOU_keras.update_state(ground_truth[:,:,0], prediction)\n",
        "print(\"Mean IoU =\", IOU_keras.result().numpy())"
      ],
      "metadata": {
        "id": "5S8impmPuvd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MeanIoU for all images"
      ],
      "metadata": {
        "id": "e3SZIgRXEssy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "IoU_values = []\n",
        "for img in range(0, a.shape[0]):\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    temp_img_input=np.expand_dims(temp_img, 0)\n",
        "    prediction = (model.predict(temp_img_input)[0,:,:,0] > 0.5).astype(np.uint8)\n",
        "    \n",
        "    IoU = MeanIoU(num_classes=n_classes)\n",
        "    IoU.update_state(ground_truth[:,:,0], prediction)\n",
        "    IoU = IoU.result().numpy()\n",
        "    IoU_values.append(IoU)\n",
        "\n",
        "    print(IoU)\n",
        "    \n",
        "df = pd.DataFrame(IoU_values, columns=[\"IoU\"])\n",
        "df = df[df.IoU != 1.0]\n",
        "\n",
        "mean_IoU = df.mean().values\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean IoU is: \", mean_IoU)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)\n"
      ],
      "metadata": {
        "id": "LzjkWF_RvWHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision for all images"
      ],
      "metadata": {
        "id": "po0RqGLBwBS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Precision_values = []\n",
        "for img in range(a.shape[0]):\n",
        "\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    temp_img_input=np.expand_dims(temp_img, 0)\n",
        "    prediction = (model.predict(temp_img_input)[0,:,:,0]> 0.5).astype(np.uint8)\n",
        "    precision=precision_score(ground_truth[:,:,0], prediction, average='macro',zero_division=1) # to avoid zero division\n",
        "    Precision_values.append (precision)\n",
        "    print(precision)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(Precision_values, columns=[\"Precision\"])\n",
        "df = df[df.Precision != 1.0]    \n",
        "mean_precision = df.mean().values\n",
        "std=df.std()\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean Precision is: \", mean_precision)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)"
      ],
      "metadata": {
        "id": "LrvR8OfCv_wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall for all images"
      ],
      "metadata": {
        "id": "JKjkhx-kwI-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "Recall_values = []\n",
        "for img in range(a.shape[0]):\n",
        "\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    temp_img_input=np.expand_dims(temp_img, 0)\n",
        "    prediction = (model.predict(temp_img_input)[0,:,:,0]> 0.5).astype(np.float32)\n",
        "    recall=recall_score(ground_truth[0,:,:,0], prediction, average='macro',zero_division=1) # to avoid zero division\n",
        "    Recall_values.append (recall)\n",
        "    print(recall)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(Recall_values, columns=[\"Recall\"])\n",
        "df = df[df.Recall != 1.0]    \n",
        "boxplot = df.boxplot(grid=False,vert=True,color='blue')\n",
        "mean_rec = df.mean().values\n",
        "std=df.std()\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean Recall is: \", mean_rec)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)"
      ],
      "metadata": {
        "id": "6hGNXJ3vwItf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary Accuracy for all images"
      ],
      "metadata": {
        "id": "3Zztz_sqv16q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BinaryAccuracy_values = []\n",
        "for img in range(a.shape[0]):\n",
        "      temp_img = a[img]\n",
        "      ground_truth=b[img]\n",
        "      temp_img_input=np.expand_dims(temp_img, 0)\n",
        "      prediction = (model.predict(temp_img_input)[0,:,:,0]> 0.5).astype(np.uint8)\n",
        "      Accuracy=BinaryAccuracy()\n",
        "      Accuracy.update_state(ground_truth[:,:,0], prediction)\n",
        "      Accuracy = Accuracy.result().numpy()\n",
        "      BinaryAccuracy_values.append(Accuracy)\n",
        "\n",
        "      print(Accuracy)\n",
        "      \n",
        "\n",
        "df = pd.DataFrame(BinaryAccuracy_values, columns=[\"BinaryAccuracy\"])\n",
        "df = df[df.BinaryAccuracy != 1.0]    \n",
        "mean_acc = df.mean().values\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "\n",
        "print(\"Mean Binary Accuracy is: \", mean_acc)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)\n"
      ],
      "metadata": {
        "id": "pnZ__02Tv1Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Final Metrics excluding black masks and first slices\n",
        "\n"
      ],
      "metadata": {
        "id": "HgOl23N8wYk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "IoU_values = []\n",
        "n_pixel_true=[]\n",
        "n_pixel_predicted=[]\n",
        "for img in range(70,a.shape[0]): #70 represents the number of slice in which the IoU starts to be high. Here the predicted masks and the real masks are similar. This starting value changes from patient to patient.\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    if (ground_truth.max()>0):\n",
        "        temp_img_input=np.expand_dims(temp_img, 0)\n",
        "        prediction = (model.predict(temp_img_input)[0,:,:,0]>0.5).astype(np.uint8) # if there are values greater than 0 , the real mask contains useful information and cannot be discarded\n",
        "      \n",
        "        n_pixel_true1=ground_truth.sum() #real area\n",
        "        n_pixel_predicted1=prediction.sum() #predicted area\n",
        "        IoU = MeanIoU(num_classes=n_classes)\n",
        "        IoU.update_state(ground_truth[:,:,0], prediction)\n",
        "        IoU = IoU.result().numpy()\n",
        "        IoU_values.append(IoU)\n",
        "        n_pixel_true.append(n_pixel_true1)\n",
        "        n_pixel_predicted.append(n_pixel_predicted1)\n",
        "\n",
        "\n",
        "\n",
        "        print(IoU)\n",
        "  \n",
        "\n",
        "df = pd.DataFrame(IoU_values, columns=[\"IoU\"])\n",
        "df = df[df.IoU != 1.0]    \n",
        "mean_IoU = df.mean().values\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print('Number of masks is', len(IoU_values))\n",
        "print(\"Mean IoU is: \", mean_IoU)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)\n",
        "     "
      ],
      "metadata": {
        "id": "vLnicpt2v-1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary Accuracy\n"
      ],
      "metadata": {
        "id": "SqGtiGM7xVG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BinaryAccuracy_values = []\n",
        "for img in range(70,a.shape[0]): #70 represents the number of slice in which the IoU starts to be high. Here the predicted masks and the real masks are similar. This starting value changes from patient to patient.\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    if (ground_truth.max()>0):\n",
        "        temp_img_input=np.expand_dims(temp_img, 0)\n",
        "        prediction = (model.predict(temp_img_input)[0,:,:,0]>0.5).astype(np.uint8) # if there are values greater than 0 , the real mask contains useful information and cannot be discarded\n",
        "\n",
        "\n",
        "        Accuracy=BinaryAccuracy()\n",
        "        Accuracy.update_state(ground_truth[:,:,0], prediction)\n",
        "        Accuracy = Accuracy.result().numpy()\n",
        "        BinaryAccuracy_values.append(Accuracy)\n",
        "\n",
        "        print(Accuracy)\n",
        "      \n",
        "\n",
        "df = pd.DataFrame(BinaryAccuracy_values, columns=[\"BinaryAccuracy\"])\n",
        "df = df[df.BinaryAccuracy != 1.0]    \n",
        "mean_acc = df.mean().values\n",
        "std=df.std()\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean Accuracy is: \", mean_acc)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)"
      ],
      "metadata": {
        "id": "A6xCC8HIxTsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision"
      ],
      "metadata": {
        "id": "jJccgggmxb8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "Precision_values = []\n",
        "for img in range(70,a.shape[0]): #70 represents the number of slice in which the IoU starts to be high. Here the predicted masks and the real masks are similar. This starting value changes from patient to patient.\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    if (ground_truth.max()>0):\n",
        "        temp_img_input=np.expand_dims(temp_img, 0)\n",
        "        prediction = (model.predict(temp_img_input)[0,:,:,0]>0.5).astype(np.uint8) # if there are values greater than 0 , the real mask contains useful information and cannot be discarded\n",
        "\n",
        "\n",
        "        precision=precision_score(ground_truth[:,:,0], prediction, average='macro',zero_division=1)\n",
        "        Precision_values.append (precision)\n",
        "        print(precision)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(Precision_values, columns=[\"Precision\"])\n",
        "df = df[df.Precision != 1.0]    \n",
        "mean_precision = df.mean().values\n",
        "std=df.std()\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean Precision is: \", mean_precision)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)\n",
        "     "
      ],
      "metadata": {
        "id": "R0FWPXSqxatn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall"
      ],
      "metadata": {
        "id": "C8uF1HVvxrIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "Recall_values = []\n",
        "for img in range(70,a.shape[0]): #70 represents the number of slice in which the IoU starts to be high. Here the predicted masks and the real masks are similar. This starting value changes from patient to patient.\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    if (ground_truth.max()>0):\n",
        "        temp_img_input=np.expand_dims(temp_img, 0)\n",
        "        prediction = (model.predict(temp_img_input)[0,:,:,0]>0.5).astype(np.uint8) # if there are values greater than 0 , the real mask contains useful information and cannot be discarded\n",
        "\n",
        "        recall=recall_score(ground_truth[:,:,0], prediction, average='macro',zero_division=1)\n",
        "        Recall_values.append (recall)\n",
        "        print(recall)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(Recall_values, columns=[\"Recall\"])\n",
        "df = df[df.Recall != 1.0]    \n",
        "mean_rec = df.mean().values\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean Recall is: \", mean_rec)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)"
      ],
      "metadata": {
        "id": "LfNsLgAoxp0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sequential U-Net**"
      ],
      "metadata": {
        "id": "0NVJev7GK9ER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Drive"
      ],
      "metadata": {
        "id": "dYJgJ4O8K696"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/gdrive\")"
      ],
      "metadata": {
        "id": "p4xOAxrtle_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "JSIJ62x_lkNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.core.completer import time\n",
        "from natsort import natsorted\n",
        "from tensorflow.keras.preprocessing.image import (\n",
        "    array_to_img,\n",
        "    img_to_array,\n",
        "    load_img,\n",
        ")\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "XUaNoEZ5loft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Loader and Data Augmentation"
      ],
      "metadata": {
        "id": "CEghkAWPlsjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Through the current Data Loader it is possible to take the time series Im(t), Im(t + 1),Im(t + 2), and the mask associated with the last of this sequence, with overlap.\n",
        "Data Augmentation is performed."
      ],
      "metadata": {
        "id": "breH9IYEn2gA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        data_path,\n",
        "        timesteps: int = 3, #time steps\n",
        "        batch_size: int = 12, #batch size\n",
        "        squeeze=False, \n",
        "        augmentation=True,\n",
        "        sort_method=\"natsort\" #sort method\n",
        "    ):\n",
        "\n",
        "        self.do_augmentation = augmentation\n",
        "        self.timesteps = timesteps\n",
        "        self.batch_size = 12\n",
        "        self.squeeze = squeeze\n",
        "        self.data_path = data_path\n",
        "        train_img_file_names = [\n",
        "            os.path.join(data_path, fn)\n",
        "            for fn in os.listdir(\n",
        "                data_path\n",
        "            )  #\n",
        "        ]\n",
        "        def sort_by_number(file_names:str):\n",
        "            return sorted(names, key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
        "\n",
        "        train_img_file_names = natsorted(train_img_file_names) if sort_method == \"natsort\" else sort_by_number(train_img_file_names) # sorting images\n",
        "     \n",
        "        train_mask_file_names = [\n",
        "            fn.replace(\"images\", \"masks\") for fn in train_img_file_names   #sorting masks\n",
        "        ]\n",
        "        self.imgs = (\n",
        "            np.array(\n",
        "                [\n",
        "                    img_to_array(load_img(fn, color_mode=\"grayscale\"))\n",
        "                    for fn in train_img_file_names\n",
        "                ]\n",
        "            )\n",
        "            / 255 #rescale the images\n",
        "        )\n",
        "        self.masks = (\n",
        "            np.array(\n",
        "                [\n",
        "                    img_to_array(load_img(fn, color_mode=\"grayscale\"))\n",
        "                    for fn in train_mask_file_names\n",
        "                ]\n",
        "            )\n",
        "            / 255 #rescale the masks\n",
        "            > 0.5 #Binarize the masks\n",
        "        ).astype(float)\n",
        "        #Data Augmentation\n",
        "        self.augmentation = tf.keras.Sequential(   \n",
        "            [\n",
        "                layers.RandomFlip(\"horizontal_and_vertical\"), #random flip in horizontal and vertical axis\n",
        "                layers.RandomRotation(0.2), #random rotation\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    #Creating the Generators\n",
        "    def __next__(self):\n",
        "        xs = []\n",
        "        ys = []\n",
        "        for _ in range(self.batch_size):\n",
        "            index = np.random.randint(0, len(self.imgs) - self.timesteps)\n",
        "            xs.append(self.imgs[index : index + self.timesteps])\n",
        "            ys.append(self.masks[index + self.timesteps])\n",
        "        x, y = np.array(xs), np.array(ys)\n",
        "        x = x.squeeze(-1).transpose(0, 2, 3, 1)\n",
        "        xy = tf.concat((x, y), axis=-1)\n",
        "        if self.do_augmentation:\n",
        "            xy = self.augmentation(xy)\n",
        "\n",
        "        x = xy[:, :, :, :3]\n",
        "        y = xy[:, :, :, 3:]\n",
        "        if not self.squeeze:\n",
        "            x = tf.transpose(x, perm=(0, 3, 1, 2))[..., None]\n",
        "            y = tf.expand_dims(y, 1)\n",
        "        return x, y\n",
        "     "
      ],
      "metadata": {
        "id": "6rImCNRBlwmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Generators. The first generator is for training images and masks and the other one is for validation. These generators will be the input of the model."
      ],
      "metadata": {
        "id": "cGigz4mOp5cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    data_path=os.path.join(\n",
        "        \"/gdrive/MyDrive/\" , \"train_images\", \"images\" # training images path\n",
        "    ),\n",
        "    batch_size=12,\n",
        "    squeeze=False, #if squeeze is True, the output tensors are 2D , if False the output tensors are 3D\n",
        "    augmentation=True, #Data Augmentation is applied simultaneously to trainining images and masks\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    data_path=os.path.join(\n",
        "        \"/gdrive/MyDrive/\",\n",
        "        \"validation_images\", \"images\" # validation images path\n",
        "    ),\n",
        "    batch_size=12,\n",
        "    squeeze=False,\n",
        "    augmentation=False, #Data Augmentation is not applied to validation set. Data Loader is used to produce the final tensor with the correct shape and to rescale the images and binarize the masks.\n",
        "\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "b8pFiNqOo4Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifying generators\n",
        "\n",
        "Show some example of augmented images and check if they are associated in correct way to the masks\n",
        "\n"
      ],
      "metadata": {
        "id": "vrmBcs4PqCPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x, y = train_loader.__next__()\n",
        "\n",
        "for i in range(0,12):\n",
        "    image = x[i,0,:,:,0]\n",
        "    mask= y[i,0,:,:,0]\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "xanF_-83qKLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if images and masks are rescaled. Values must be between 0 and 1 for images and 0 or 1 for masks\n",
        "\n"
      ],
      "metadata": {
        "id": "k1t7qIi4qQUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(x.max())\n",
        "print(y.max())"
      ],
      "metadata": {
        "id": "8DwA1V_5qP_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if tensors have the correct shape.\n",
        "Images shape must be equal to ( *batch size*, *time steps*, *height*, *width*, *number of channels* )\n",
        "\n",
        "Masks shape must be equal to ( *batch size*, *time steps*,*height*,*width*, *number of channels*)"
      ],
      "metadata": {
        "id": "nbRA5P-NqiPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "lECeMt_7qXRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x, y = val_loader.__next__()\n",
        "\n",
        "for i in range(0,3):\n",
        "    image = x[i,0,:,:,0]\n",
        "    mask= y[i,0,:,:,0]\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bIESjjKtrYVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model"
      ],
      "metadata": {
        "id": "3G-t8qHLspPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries\n"
      ],
      "metadata": {
        "id": "vsDQN6elRyuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, TimeDistributed,Dropout,Input, Dense,\\\n",
        "    BatchNormalization, GRU, Layer, Flatten,MaxPooling2D, concatenate,Lambda\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from tensorflow.python.keras.layers import ConvLSTM2D\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "qgX4H588syoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the input shape of the model\n",
        "\n"
      ],
      "metadata": {
        "id": "dX5lfTDCtEJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_TIME_STEPS= x.shape[1]\n",
        "IMG_HEIGHT = x.shape[2]\n",
        "IMG_WIDTH  = x.shape[3]\n",
        "IMG_CHANNELS = x.shape[4]\n",
        "input_shape = (IMG_TIME_STEPS,IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "print(input_shape)"
      ],
      "metadata": {
        "id": "oAqWlMPCsib0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_l = layers.Input(shape=(input_shape))\n",
        "#Contraction path\n",
        "x =  (layers.TimeDistributed(layers.Conv2D( 16, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal', activation='relu'))) (input_l)\n",
        "x=layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "conv1 = layers.TimeDistributed( layers.Conv2D( 16, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal', activation='relu' ) ) (x)\n",
        "conv1=layers.TimeDistributed(layers.BatchNormalization())(conv1)\n",
        "x=layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2,2)))(conv1)\n",
        "x = layers.TimeDistributed( layers.Conv2D( 32, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal',activation='relu' ) ) (x)\n",
        "x=layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "conv2 = layers.TimeDistributed( layers.Conv2D( 32, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal', activation='relu' ) ) (x)\n",
        "conv2=layers.TimeDistributed(layers.BatchNormalization())(conv2)\n",
        "x=layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2,2)))(conv2)\n",
        "x = layers.TimeDistributed( layers.Conv2D( 64, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal', activation='relu' ) ) (x)\n",
        "x=layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "conv3 = layers.TimeDistributed( layers.Conv2D( 64, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal', activation='relu' ) ) (x)\n",
        "conv3=layers.TimeDistributed(layers.BatchNormalization())(conv3)\n",
        "x=layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2,2)))(conv3)\n",
        "x = layers.TimeDistributed( layers.Conv2D( 128, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal', activation='relu' ) ) (x)\n",
        "x=layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "conv4 = layers.TimeDistributed( layers.Conv2D( 128, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal', activation='relu')) (x)\n",
        "conv4=layers.TimeDistributed(layers.BatchNormalization())(conv4)\n",
        "x=layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2,2)))(conv4)\n",
        "x = layers.TimeDistributed( layers.Conv2D( 256, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal', activation='relu' ) ) (x)\n",
        "x=layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "conv5 = layers.TimeDistributed( layers.Conv2D( 256, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal',activation='relu' ) ) (x)\n",
        "conv5=layers.TimeDistributed(layers.BatchNormalization())(conv5)\n",
        "# LSTM component\n",
        "x=layers.ConvLSTM2D(256,kernel_size=(3,3),padding='same',strides=(1,1),return_sequences=True,recurrent_dropout=0.2))(conv5)\n",
        "#Expansive path\n",
        "up1 = layers.TimeDistributed( layers.Conv2DTranspose(128,kernel_size=(3,3),padding='same',strides=(2,2)))(x)\n",
        "concat1 = layers.concatenate([up1, conv4])\n",
        "x = layers.TimeDistributed( layers.Conv2D( 128, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal', activation='relu' ) ) (concat1)\n",
        "x=layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "x = layers.TimeDistributed( layers.Conv2D( 128, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal', activation='relu') ) (x)\n",
        "x=layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "up2 = layers.TimeDistributed( layers.Conv2DTranspose( 64,kernel_size=(3,3),padding='same',strides=(2,2)))(x)\n",
        "concat2 = layers.concatenate([up2, conv3])\n",
        "x = layers.TimeDistributed( layers.Conv2D( 64, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal', activation='relu' ) ) (concat2)\n",
        "x=layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "x = layers.TimeDistributed( layers.Conv2D( 64, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal', activation='relu' ) ) (x)\n",
        "x=layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "up3 = layers.TimeDistributed( layers.Conv2DTranspose( 32,kernel_size=(3,3),padding='same',strides=(2,2)))(x)\n",
        "concat3 = layers.concatenate([up3, conv2])\n",
        "x = layers.TimeDistributed( layers.Conv2D( 32, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal',activation='relu') ) (concat3)\n",
        "x=layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "x = layers.TimeDistributed( layers.Conv2D( 32, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal',activation='relu') ) (x)\n",
        "x=layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "up4= layers.TimeDistributed( layers.Conv2DTranspose( 16,kernel_size=(3,3),padding='same',strides=(2,2)))(x)\n",
        "concat4 = layers.concatenate([up4, conv1])\n",
        "x = layers.TimeDistributed( layers.Conv2D( 16, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal', activation='relu') ) (concat4)\n",
        "x=layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "x = layers.TimeDistributed( layers.Conv2D( 16, kernel_size=(3, 3),padding='same',strides=(1,1),kernel_initializer='he_normal',activation='relu') ) (x)\n",
        "x=layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "#LSTM component\n",
        "x=layers.ConvLSTM2D(16,kernel_size=(3,3),padding='same',strides=(1,1),return_sequences=False,recurrent_dropout=0.2))(x)\n",
        "x=tf.expand_dims(x,axis=1)\n",
        "out = layers.Conv2D( 1, kernel_size=(1, 1),padding='same',strides=(1,1), activation='sigmoid' )  (x)\n"
      ],
      "metadata": {
        "id": "deB29hJRtcNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = models.Model(inputs=input_l, outputs=out)\n",
        "model.summary()\n",
        "     "
      ],
      "metadata": {
        "id": "c5yTJGkpsiY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the steps per epoch for training and validation required to train the model\n",
        "\n"
      ],
      "metadata": {
        "id": "v7ZsuVv4rkXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "num_train_imgs = len(os.listdir(\"/gdrive/MyDrive/train_images/images\") #images path\n",
        "num_val_images = len(os.listdir(\"/gdrive/MyDrive/val_images/images\") #masks path\n",
        "                     \n",
        "steps_per_epoch = num_train_imgs//batch_size\n",
        "val_steps_per_epoch = num_val_images//batch_size\n"
      ],
      "metadata": {
        "id": "HuWuEanBroYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the model metrics and losses. Dice Loss, IoU Loss, Tversky Loss, Focal Loss have been tested\n",
        "\n"
      ],
      "metadata": {
        "id": "TzRSHAkRsC1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=0.0001): #smooth factor to avoid zero division\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "\n",
        "    return ((2. * intersection + smooth) / (K.sum(y_true_f) +\n",
        "            K.sum(y_pred_f) + smooth))\n",
        "\n",
        "\n",
        "def dice_coefficient_loss(y_true, y_pred):\n",
        "    return 1.0-dice_coefficient(y_true, y_pred)\n",
        "\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred))\n",
        "    sum_ = K.sum(K.square(y_true)) + K.sum(K.square(y_pred))\n",
        "    jac = (intersection) / (sum_ - intersection)\n",
        "    return jac\n",
        "\n",
        "def iou_loss(y_true, y_pred):\n",
        "    return 1-iou(y_true, y_pred)\n",
        "\n",
        "def tversky(y_true, y_pred):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
        "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    return 1 - tversky(y_true,y_pred)"
      ],
      "metadata": {
        "id": "ZKEjQi6dsCfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python libraries for focal loss\n",
        "\n"
      ],
      "metadata": {
        "id": "cSO2TmUssJBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install focal-loss\n"
      ],
      "metadata": {
        "id": "_f9zV0TQsKmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from focal_loss import BinaryFocalLoss"
      ],
      "metadata": {
        "id": "VGDT5JQAsMUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Learning Rate and Optimizer\n",
        "\n"
      ],
      "metadata": {
        "id": "jD8qcj68uwWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 5e-5\n",
        "optim = tf.keras.optimizers.Adam(LR) #Adaptive Moment Estimation Optimizer"
      ],
      "metadata": {
        "id": "IQLl3rVOuvK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Metrics used\n",
        "\n"
      ],
      "metadata": {
        "id": "_uTr2cklu7wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [iou, dice_coefficient, 'binary_accuracy','Recall','Precision']"
      ],
      "metadata": {
        "id": "tXb59aWcu6_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model\n",
        "\n"
      ],
      "metadata": {
        "id": "yKZR4QiNvE9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Dice loss is chosen as loss function\n"
      ],
      "metadata": {
        "id": "dd3CR3HPvK9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(optimizer=optim, loss=dice_coefficient_loss, metrics=metrics)\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "i9xrmEsUvAkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add callback to save the best model. The best model has the highest dice coefficient on the validation set\n",
        "\n"
      ],
      "metadata": {
        "id": "H9PFK_lGvPdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/gdrive/MyDrive/chk/',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_dice_coefficient',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "hAg7qVaavSP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model\n",
        "\n"
      ],
      "metadata": {
        "id": "jzcMT1_gvUs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history=model.fit(train_loader,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          epochs=40,\n",
        "          verbose=1,\n",
        "          validation_data=val_loader,\n",
        "          callbacks=model_checkpoint_callback,\n",
        "          validation_steps=val_steps_per_epoch)"
      ],
      "metadata": {
        "id": "ETfdleMfvXkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model in .h5 format for future use\n",
        "\n"
      ],
      "metadata": {
        "id": "sm1W6BgKvcx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_path='/gdrive/MyDrive/model.h5'"
      ],
      "metadata": {
        "id": "WfvnpB7UvcLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(model_path)"
      ],
      "metadata": {
        "id": "PpdCYhFLvgE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation on Validation Set"
      ],
      "metadata": {
        "id": "5aSapE1kvjLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load previously saved model\n",
        "\n"
      ],
      "metadata": {
        "id": "QJzdnkYbvo-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(model_path,compile=False)"
      ],
      "metadata": {
        "id": "7ajtLiCqvnk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation is performed directly in batches "
      ],
      "metadata": {
        "id": "NFIQFhrVxNEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DataLoader:\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        data_path,\n",
        "        timesteps: int = 3,\n",
        "        batch_size: int = 477, \n",
        "        squeeze=False,\n",
        "        augmentation=True,\n",
        "        sort_method=\"natsort\" \n",
        "    ):\n",
        "\n",
        "        self.do_augmentation = augmentation\n",
        "        self.timesteps = timesteps\n",
        "        self.batch_size = 477 # number of images and masks within the validation set\n",
        "        self.squeeze = squeeze\n",
        "        self.data_path = data_path\n",
        "        train_img_file_names = [\n",
        "            os.path.join(data_path, fn)\n",
        "            for fn in os.listdir(\n",
        "                data_path\n",
        "            )  \n",
        "        ]\n",
        "        def sort_by_number(file_names:str):\n",
        "            return sorted(names, key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
        "\n",
        "        train_img_file_names = natsorted(train_img_file_names) if sort_method == \"natsort\" else sort_by_number(train_img_file_names)\n",
        "\n",
        "        train_mask_file_names = [\n",
        "            fn.replace(\"images\", \"masks\") for fn in train_img_file_names\n",
        "        ]\n",
        "        self.imgs = (\n",
        "            np.array(\n",
        "                [\n",
        "                    img_to_array(load_img(fn, color_mode=\"grayscale\")) #grayscale. Channel number is equal to 1\n",
        "                    for fn in train_img_file_names\n",
        "                ]\n",
        "            )\n",
        "            / 255 #rescale the images\n",
        "        )\n",
        "        self.masks = (\n",
        "            np.array(\n",
        "                [\n",
        "                    img_to_array(load_img(fn, color_mode=\"grayscale\")) #grayscale. Channel number is equal to 1\n",
        "                    for fn in train_mask_file_names\n",
        "                ]\n",
        "            )\n",
        "            / 255 #recsale the masks\n",
        "            > 0.5 #binarize the masks\n",
        "        ).astype(float)\n",
        "        self.augmentation = tf.keras.Sequential(\n",
        "            [\n",
        "                layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "                layers.RandomRotation(0.2),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "   #Creating the Generator\n",
        "\n",
        "    def __next__(self):\n",
        "        xs = []\n",
        "        ys = []\n",
        "        for _ in range(self.batch_size):\n",
        "            index = np.random.randint(0, len(self.imgs) - self.timesteps)\n",
        "            xs.append(self.imgs[index : index + self.timesteps])\n",
        "            ys.append(self.masks[index + self.timesteps])\n",
        "        x, y = np.array(xs), np.array(ys)\n",
        "        x = x.squeeze(-1).transpose(0, 2, 3, 1)\n",
        "        xy = tf.concat((x, y), axis=-1)\n",
        "        if self.do_augmentation:\n",
        "            xy = self.augmentation(xy)\n",
        "\n",
        "        x = xy[:, :, :, :3]\n",
        "        y = xy[:, :, :, 3:]\n",
        "        if not self.squeeze:\n",
        "            x = tf.transpose(x, perm=(0, 3, 1, 2))[..., None]\n",
        "            y = tf.expand_dims(y, 1)\n",
        "        return x, y\n",
        "     "
      ],
      "metadata": {
        "id": "JqWZkDb3xHjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "val_loader = DataLoader(\n",
        "    data_path=os.path.join(\n",
        "        \"/gdrive/MyDrive/\",\n",
        "        \"validation_images\", \"images\"\n",
        "    ),\n",
        "    batch_size=477, # number of images and masks within the validation set\n",
        "    squeeze=False,\n",
        "    augmentation=False,\n",
        ")"
      ],
      "metadata": {
        "id": "eEen_PanxdJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a, b = val_loader.__next__()"
      ],
      "metadata": {
        "id": "DCFqN9zqxteM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction on random images in the validation set\n",
        "\n"
      ],
      "metadata": {
        "id": "PjVws3azxoXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import random\n",
        "\n",
        "test_img_number = random.randint(a.shape[0]) # random value from 0 to the number of images in the validation set\n",
        "test_img = a[test_img_number] #testing image\n",
        "ground_truth=b[test_img_number] # real mask\n",
        "test_img_input=np.expand_dims(test_img, 0) #prediction on testing image \n",
        "prediction = (model.predict(test_img_input)[0,0,:,:,0] > 0.5).astype(np.uint8)\n",
        "     "
      ],
      "metadata": {
        "id": "bcvzNbyoxn0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show random examples\n",
        "\n"
      ],
      "metadata": {
        "id": "onUMd8gXyc-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing image, predicted mask and real mask can be displayed\n",
        "\n"
      ],
      "metadata": {
        "id": "RNNb9OL3yewY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  plt.figure(figsize=(16, 8))\n",
        "  plt.subplot(231)\n",
        "  plt.axis('off')\n",
        "  plt.title('Testing Image')\n",
        "  plt.imshow(test_img[0,:,:,0], cmap='gray')\n",
        "\n",
        "\n",
        "  plt.subplot(232)\n",
        "  plt.title('Real Mask ')\n",
        "  plt.axis('off')\n",
        "  plt.imshow(ground_truth[0,:,:,0], cmap='gray')\n",
        "  plt.subplot(233)\n",
        "  plt.axis('off')\n",
        "  plt.title('Predicted mask')\n",
        "  plt.imshow(prediction, cmap='gray')\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "BusGymCMyXWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the Mean Intersection Over Union metric from keras metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "y1CXNw-cykBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import MeanIoU\n"
      ],
      "metadata": {
        "id": "0bz9Jp8OyXLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the MeanIoU for a single image\n",
        "\n"
      ],
      "metadata": {
        "id": "vnwTrpJEypv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n_classes = 2 # 2 classes for binary segmentation\n",
        "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "IOU_keras.update_state(ground_truth[:,:,0], prediction)\n",
        "print(\"Mean IoU =\", IOU_keras.result().numpy())\n",
        "     "
      ],
      "metadata": {
        "id": "vxsodX8lyrvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the meanIoU of each image in the validation set. The MeanIoU for each image can be displayed and the final average value on all the predictions is computed\n",
        "\n"
      ],
      "metadata": {
        "id": "4HR7ot8Jyz9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "IoU_values = []\n",
        "for img in range(0, a.shape[0]):\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    temp_img_input=np.expand_dims(temp_img, 0)\n",
        "    prediction = (model.predict(temp_img_input)[0,0,:,:,0]> 0.5).astype(np.uint8)\n",
        "    \n",
        "    IoU = MeanIoU(num_classes=n_classes)\n",
        "    IoU.update_state(ground_truth[0,:,:,0], prediction)\n",
        "    IoU = IoU.result().numpy()\n",
        "    IoU_values.append(IoU)\n",
        "\n",
        "    print(IoU)\n",
        "    \n",
        "\n",
        "\n",
        "df = pd.DataFrame(IoU_values, columns=[\"IoU\"])\n",
        "df = df[df.IoU != 1.0]    \n",
        "mean_IoU = df.mean().values\n",
        "print(\"Mean IoU is: \", mean_IoU)"
      ],
      "metadata": {
        "id": "j8TN1hfHzAeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation on Test Set"
      ],
      "metadata": {
        "id": "jHEmdW7RzE4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21 subjects are used to test the model performance. Images and masks of testing dataset were preprocessed in the same way of training and validation ones. 21 folders were created each containing the images and the corresponding masks."
      ],
      "metadata": {
        "id": "f49N5zRpzLpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Drive\n",
        "\n"
      ],
      "metadata": {
        "id": "MRq8s3o8zPCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/gdrive\")"
      ],
      "metadata": {
        "id": "Yzu0U5nJzTQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "3njcqbTizQtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from tensorflow.keras.metrics import MeanIoU, Recall, Precision, BinaryAccuracy, IoU\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from glob import glob\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "import os\n",
        "from IPython.core.completer import time\n",
        "from skimage.transform import resize\n",
        "from natsort import natsorted\n",
        "from tensorflow.keras.preprocessing.image import (\n",
        "    array_to_img,\n",
        "    img_to_array,\n",
        "    load_img,\n",
        ")\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow.keras import backend as K\n"
      ],
      "metadata": {
        "id": "hbh1vZJezVjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader:\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        data_path,\n",
        "        paziente: str,\n",
        "        timesteps: int = 3,\n",
        "        squeeze=False,\n",
        "        augmentation=False,\n",
        "        shuffle=False,\n",
        "        sort_method=\"natsort\", \n",
        "    ):\n",
        "        self.shuffle = shuffle\n",
        "        self.do_augmentation = augmentation\n",
        "        self.timesteps = timesteps\n",
        "        self.batch_size = batch_size\n",
        "        self.squeeze = squeeze\n",
        "        self.data_path = data_path\n",
        "        train_img_file_names = [\n",
        "            os.path.join(data_path, fn)\n",
        "            for fn in os.listdir(\n",
        "                data_path\n",
        "            ) \n",
        "        ]\n",
        "\n",
        "        train_img_file_names = (\n",
        "            natsorted(train_img_file_names)\n",
        "            if sort_method == \"natsort\"\n",
        "            else sort_by_number(train_img_file_names)\n",
        "        )\n",
        "        self.filenames = train_img_file_names\n",
        "        train_mask_file_names = [\n",
        "            fn.replace(\"images\", \"masks\") for fn in train_img_file_names\n",
        "        ]\n",
        "        if not os.path.exists(f\"{paziente}imgs.pickle\"):   #save sorted images into drive\n",
        "            self.imgs = (\n",
        "                np.array(\n",
        "                    [\n",
        "                        resize(\n",
        "                            img_to_array(load_img(fn, color_mode=\"grayscale\")),\n",
        "                            (resize_to, resize_to),\n",
        "                        )\n",
        "                        for fn in train_img_file_names\n",
        "                    ]\n",
        "                )\n",
        "                / 255 # rescale the images \n",
        "            )\n",
        "            with open(f\"{paziente}imgs.pickle\", \"wb\") as f: #load sorted images from drive\n",
        "                pickle.dump(self.imgs, f)\n",
        "        else:\n",
        "            print(\"Loading imgs from pickle\")\n",
        "            with open(f\"{paziente}imgs.pickle\", \"rb\") as f:\n",
        "                self.imgs = pickle.load(f)\n",
        "        if not os.path.exists(f\"{paziente}_masks.pickle\"): #save sorted masks into drive\n",
        "            self.masks = (\n",
        "                np.array(\n",
        "                    [\n",
        "                        resize(\n",
        "                            img_to_array(load_img(fn, color_mode=\"grayscale\")),\n",
        "                            (resize_to, resize_to),\n",
        "                        )\n",
        "                        for fn in train_mask_file_names\n",
        "                    ]\n",
        "                )\n",
        "                / np.array(255) #rescale the masks\n",
        "                > 0.5 #Binarize the masks\n",
        "            ).astype(float)\n",
        "            with open(f\"{paziente}masks.pickle\", \"wb\") as f:# load sorted masks from drive\n",
        "                pickle.dump(self.masks, f)\n",
        "        else:\n",
        "            print(\"Loading masks from pickle file\")\n",
        "            with open(f\"{paziente}masks.pickle\", \"rb\") as f:\n",
        "                self.masks = pickle.load(f)\n",
        "\n",
        "        self.augmentation = tf.keras.Sequential(\n",
        "            [\n",
        "                layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "                layers.RandomRotation(0.2),\n",
        "            ]\n",
        "        )\n",
        "        self.index = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        imgs = np.stack(\n",
        "            [\n",
        "                self.imgs[i : i + 3]\n",
        "                for i in range(0, len(self.imgs))\n",
        "                if i + 3 < len(self.imgs)\n",
        "            ]\n",
        "        )\n",
        "        masks = np.stack(\n",
        "            [\n",
        "                self.masks[i, None]\n",
        "                for i in range(0, len(self.masks))\n",
        "                if i + 3 < len(self.masks)\n",
        "            ]\n",
        "        )\n",
        "        return imgs, masks\n"
      ],
      "metadata": {
        "id": "Enz_gtPe3VC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_loader = DataLoader(\n",
        "        data_path=os.path.join(\n",
        "                   \"/gdrive/MyDrive/\",\n",
        "        \"test_images\", \"images\",\n",
        "        ),\n",
        "\n",
        "        paziente=\"1\", \n",
        "        squeeze=False,\n",
        "        augmentation=False,\n",
        "        shuffle=False,\n",
        "        sort_method=\"number\",\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "iZbVBTHh4sz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a, b = test_loader.__next__()"
      ],
      "metadata": {
        "id": "c8n7JYRX5JaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load previously saved model\n"
      ],
      "metadata": {
        "id": "cNWqFuP-zcGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_path='/gdrive/MyDrive/model.h5'"
      ],
      "metadata": {
        "id": "xdHlIfkTzcdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = load_model(model_path, compile=False)\n"
      ],
      "metadata": {
        "id": "XlCx5Yy8zgzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction on random images of the test set\n",
        "\n"
      ],
      "metadata": {
        "id": "VoRE07Gs5SX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "  test_img_number = random.randint(0,a.shape[0]) #random number\n",
        "  test_img = a[test_img_number] #Testing Image\n",
        "  ground_truth = b[test_img_number] #Real Mask\n",
        "  test_img_input = np.expand_dims(test_img, 0)\n",
        "\n",
        "  prediction = (model.predict(test_img_input)[0, 0, :, :, 0] > 0.5).astype(np.uint8) #Predicted mask\n",
        "  plt.figure(figsize=(16, 8))\n",
        "  \n",
        "  plt.subplot(231)\n",
        "  plt.axis(\"off\")\n",
        "  plt.title(\"Testing Image\")\n",
        "  plt.imshow(test_img[0, :, :, 0], cmap=\"gray\")\n",
        "\n",
        "  plt.subplot(232)\n",
        "  plt.title(\"Real Mask \")\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(ground_truth[0, :, :, 0], cmap=\"gray\")\n",
        "  plt.subplot(233)\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "  plt.title(\"Predicted mask\")\n",
        "  plt.imshow(prediction, cmap=\"gray\")\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "9hok0NXG5Uso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MeanIoU for a single image\n",
        "\n"
      ],
      "metadata": {
        "id": "v5agEf315pzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import MeanIoU\n",
        "n_classes = 2\n",
        "IOU_keras = MeanIoU(num_classes=n_classes)\n",
        "IOU_keras.update_state(ground_truth[0, :, :, 0], prediction)\n",
        "print(\"Mean IoU =\", IOU_keras.result().numpy())"
      ],
      "metadata": {
        "id": "ggZh1N185mQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MeanIoU for all images\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K6zCZg7O51M3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "IoU_values = []\n",
        "for img in range(a.shape[0]):\n",
        "    temp_img = a[img]\n",
        "    ground_truth = b[img]\n",
        "    temp_img_input = np.expand_dims(temp_img, 0)\n",
        "    prediction = (model.predict(temp_img_input)[0, 0, :, :, 0] > 0.5).astype(np.uint8)\n",
        "\n",
        "    IoU = MeanIoU(num_classes=n_classes)\n",
        "    IoU.update_state(ground_truth[0, :, :, 0], prediction)\n",
        "    IoU = IoU.result().numpy()\n",
        "    IoU_values.append(IoU)\n",
        "\n",
        "    print(IoU)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(IoU_values, columns=[\"IoU\"])\n",
        "df = df[df.IoU != 1.0]\n",
        "\n",
        "mean_IoU = df.mean().values\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean IoU is: \", mean_IoU)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)"
      ],
      "metadata": {
        "id": "UaZi6aXY5v3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary Accuracy for all images"
      ],
      "metadata": {
        "id": "Ha2k7T456ZGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "BinaryAccuracy_values = []\n",
        "for img in range(a.shape[0]):\n",
        "      temp_img = a[img]\n",
        "      ground_truth=b[img]\n",
        "      temp_img_input=np.expand_dims(temp_img, 0)\n",
        "      prediction = (model.predict(temp_img_input)[0,0,:,:,0]> 0.5).astype(np.float32)\n",
        "      Accuracy=BinaryAccuracy()\n",
        "      Accuracy.update_state(ground_truth[:,:,0], prediction)\n",
        "      Accuracy = Accuracy.result().numpy()\n",
        "      BinaryAccuracy_values.append(Accuracy)\n",
        "\n",
        "      print(Accuracy)\n",
        "      \n",
        "\n",
        "df = pd.DataFrame(BinaryAccuracy_values, columns=[\"BinaryAccuracy\"])\n",
        "df = df[df.BinaryAccuracy != 1.0]    \n",
        "mean_acc = df.mean().values\n",
        "std=df.std()\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean Accuracy is: \", mean_acc)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)\n",
        "\n"
      ],
      "metadata": {
        "id": "d4By4AC96YCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall for all images"
      ],
      "metadata": {
        "id": "On42ZVzr66fY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Recall_values = []\n",
        "for img in range(a.shape[0]):\n",
        "\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    temp_img_input=np.expand_dims(temp_img, 0)\n",
        "    prediction = (model.predict(temp_img_input)[0,0,:,:,0]> 0.5).astype(np.float32)\n",
        "    recall=recall_score(ground_truth[0,:,:,0], prediction, average='macro',zero_division=1) # to avoid zero division\n",
        "    Recall_values.append (recall)\n",
        "    print(recall)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(Recall_values, columns=[\"Recall\"])\n",
        "df = df[df.Recall != 1.0]    \n",
        "boxplot = df.boxplot(grid=False,vert=True,color='blue')\n",
        "mean_rec = df.mean().values\n",
        "std=df.std()\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean Recall is: \", mean_rec)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)"
      ],
      "metadata": {
        "id": "f8jnOVZ164fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision for all images"
      ],
      "metadata": {
        "id": "kjlRaIcS7JVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Precision_values = []\n",
        "for img in range(a.shape[0]):\n",
        "\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    temp_img_input=np.expand_dims(temp_img, 0)\n",
        "    prediction = (model.predict(temp_img_input)[0,0,:,:,0]> 0.5).astype(np.float32)\n",
        "    precision=precision_score(ground_truth[0,:,:,0], prediction, average='macro',zero_division=1) # to avoid zero division\n",
        "    Precision_values.append (precision)\n",
        "    print(precision)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(Precision_values, columns=[\"Precision\"])\n",
        "df = df[df.Precision != 1.0]    \n",
        "mean_precision = df.mean().values\n",
        "std=df.std()\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean Precision is: \", mean_precision)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)"
      ],
      "metadata": {
        "id": "_Pzm58YA7IDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Final Metrics excluding black masks and first slices "
      ],
      "metadata": {
        "id": "wL7K1l0Z7-Yq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean IoU"
      ],
      "metadata": {
        "id": "vxqcIqt08eGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IoU_values = []\n",
        "n_pixel_true=[]\n",
        "n_pixel_predicted=[]\n",
        "for img in range(70,a.shape[0]): #70 represents the number of slice in which the IoU starts to be high. Here the predicted masks and the real masks are similar. This starting value changes from patient to patient.\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    if (ground_truth.max()>0):\n",
        "        temp_img_input=np.expand_dims(temp_img, 0)\n",
        "        prediction = (model.predict(temp_img_input)[0,0,:,:,0]>0.5).astype(np.uint8) # if there are values greater than 0 , the real mask contains useful information and cannot be discarded\n",
        "      \n",
        "        n_pixel_true1=ground_truth.sum() #real area\n",
        "        n_pixel_predicted1=prediction.sum() #predicted area\n",
        "        IoU = MeanIoU(num_classes=n_classes)\n",
        "        IoU.update_state(ground_truth[0,:,:,0], prediction)\n",
        "        IoU = IoU.result().numpy()\n",
        "        IoU_values.append(IoU)\n",
        "        n_pixel_true.append(n_pixel_true1)\n",
        "        n_pixel_predicted.append(n_pixel_predicted1)\n",
        "\n",
        "\n",
        "\n",
        "        print(IoU)\n",
        "  \n",
        "\n",
        "df = pd.DataFrame(IoU_values, columns=[\"IoU\"])\n",
        "df = df[df.IoU != 1.0]    \n",
        "mean_IoU = df.mean().values\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print('Number of masks is', len(IoU_values))\n",
        "print(\"Mean IoU is: \", mean_IoU)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)"
      ],
      "metadata": {
        "id": "o7msfcaU8Obt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary Accuracy"
      ],
      "metadata": {
        "id": "uwaV0Dh29uuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BinaryAccuracy_values = []\n",
        "for img in range(70,a.shape[0]): #70 represents the number of slice in which the IoU starts to be high. Here the predicted masks and the real masks are similar. This starting value changes from patient to patient.\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    if (ground_truth.max()>0):\n",
        "        temp_img_input=np.expand_dims(temp_img, 0)\n",
        "        prediction = (model.predict(temp_img_input)[0,0,:,:,0]>0.5).astype(np.uint8) # if there are values greater than 0 , the real mask contains useful information and cannot be discarded\n",
        "\n",
        "\n",
        "        Accuracy=BinaryAccuracy()\n",
        "        Accuracy.update_state(ground_truth[:,:,0], prediction)\n",
        "        Accuracy = Accuracy.result().numpy()\n",
        "        BinaryAccuracy_values.append(Accuracy)\n",
        "\n",
        "        print(Accuracy)\n",
        "      \n",
        "\n",
        "df = pd.DataFrame(BinaryAccuracy_values, columns=[\"BinaryAccuracy\"])\n",
        "df = df[df.BinaryAccuracy != 1.0]    \n",
        "mean_acc = df.mean().values\n",
        "std=df.std()\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean Accuracy is: \", mean_acc)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)"
      ],
      "metadata": {
        "id": "nCcl59Nu9wsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall"
      ],
      "metadata": {
        "id": "o5bLucfi9__9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Recall_values = []\n",
        "for img in range(70,a.shape[0]): #70 represents the number of slice in which the IoU starts to be high. Here the predicted masks and the real masks are similar. This starting value changes from patient to patient.\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    if (ground_truth.max()>0):\n",
        "        temp_img_input=np.expand_dims(temp_img, 0)\n",
        "        prediction = (model.predict(temp_img_input)[0,0,:,:,0]>0.5).astype(np.uint8) # if there are values greater than 0 , the real mask contains useful information and cannot be discarded\n",
        "\n",
        "        recall=recall_score(ground_truth[0,:,:,0], prediction, average='macro',zero_division=1)\n",
        "        Recall_values.append (recall)\n",
        "        print(recall)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(Recall_values, columns=[\"Recall\"])\n",
        "df = df[df.Recall != 1.0]    \n",
        "boxplot = df.boxplot(grid=False,vert=True,color='blue')\n",
        "mean_rec = df.mean().values\n",
        "std=df.std()\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean Recall is: \", mean_rec)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)"
      ],
      "metadata": {
        "id": "_B_WA70E9_Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision"
      ],
      "metadata": {
        "id": "p7ya52gO-IGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Precision_values = []\n",
        "for img in range(70,a.shape[0]): #70 represents the number of slice in which the IoU starts to be high. Here the predicted masks and the real masks are similar. This starting value changes from patient to patient.\n",
        "    temp_img = a[img]\n",
        "    ground_truth=b[img]\n",
        "    if (ground_truth.max()>0):\n",
        "        temp_img_input=np.expand_dims(temp_img, 0)\n",
        "        prediction = (model.predict(temp_img_input)[0,0,:,:,0]>0.5).astype(np.uint8) # if there are values greater than 0 , the real mask contains useful information and cannot be discarded\n",
        "\n",
        "\n",
        "        precision=precision_score(ground_truth[0,:,:,0], prediction, average='macro',zero_division=1)\n",
        "        Precision_values.append (precision)\n",
        "        print(precision)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(Precision_values, columns=[\"Precision\"])\n",
        "df = df[df.Precision != 1.0]    \n",
        "mean_precision = df.mean().values\n",
        "std=df.std()\n",
        "boxplot = df.boxplot(grid=False,vert=True,color='r') #Box Plot\n",
        "std=df.std() # Standard Deviation\n",
        "median=df.median() #Median\n",
        "\n",
        "q1=df.quantile(0.25)\n",
        "q3= df.quantile(0.75)\n",
        "iqr=q3-q1 #InterQuartile Range\n",
        "print(\"Mean Precision is: \", mean_precision)\n",
        "print(\"standard deviation is \",std)\n",
        "print('median is ',median)\n",
        "print('iqr is ',iqr)"
      ],
      "metadata": {
        "id": "mTy0LU_G-JVa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
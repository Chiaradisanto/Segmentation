{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNodt4SFIMtk07lZmSYwYmn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chiaradisanto/Segmentation/blob/main/FinalCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **Save DICOM FILES as .png images**\n",
        "\n"
      ],
      "metadata": {
        "id": "gMO0iN8GRKKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Drive"
      ],
      "metadata": {
        "id": "JUgC825tO0b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "uKsop_XQpCzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Importing libraries\n"
      ],
      "metadata": {
        "id": "-KVe8M0YPNa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd \n",
        "import os\n",
        "import scipy.ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot as plt\n",
        "from  scipy import ndimage\n",
        "\n"
      ],
      "metadata": {
        "id": "5yGhk8jGPMz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing and importing module for reading and writing DICOM files"
      ],
      "metadata": {
        "id": "E5vxApOCPtEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom\n",
        "import pydicom\n",
        "from pydicom import dcmread\n"
      ],
      "metadata": {
        "id": "2kM9yTPaPbCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**get_names** function takes as input the path of the selected subject containing the DICOM files \n",
        "\n"
      ],
      "metadata": {
        "id": "MrYANsJNP8Ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_names(path):\n",
        "    names = []\n",
        "    for root, dirnames, filenames in os.walk(path):\n",
        "        for filename in filenames:\n",
        "            _, ext = os.path.splitext(filename)\n",
        "            if ext in ['.dcm']:\n",
        "                names.append(filename)\n",
        "    return names"
      ],
      "metadata": {
        "id": "oDY57BbgP0ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DICOM files are ordered with sort function. "
      ],
      "metadata": {
        "id": "kPBY1sH3ZVk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = sorted(get_names(path)) # path of the .dicom files"
      ],
      "metadata": {
        "id": "ejgkxuCyQh4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A list containig all the DICOM files is created. \n",
        "This operation loads all DICOM images from the folder into a list for manipulation."
      ],
      "metadata": {
        "id": "LXr8DJRdZmUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = []\n",
        "for x in names:\n",
        "        files.append(pydicom.dcmread(path+'/'+x))\n",
        "len(files)\n"
      ],
      "metadata": {
        "id": "MNzkC2keQi54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that all the files contains SliceLocation in it. Otherwhise skip them\n",
        "\n"
      ],
      "metadata": {
        "id": "uNc1GT95e3ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slices = []\n",
        "skipcount = 0\n",
        "for f in files:\n",
        "    if hasattr(f, 'SliceLocation'):\n",
        "        slices.append(f)\n",
        "    else:\n",
        "        skipcount = skipcount + 1\n",
        "\n",
        "print(\"skipped, no SliceLocation: {}\".format(skipcount))"
      ],
      "metadata": {
        "id": "NzYvHGsEQqTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slices are sorted according to SliceLocation"
      ],
      "metadata": {
        "id": "BfKGH68zdmhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slices = sorted(slices, key=lambda s: s.SliceLocation, reverse=True)  #reverse is True to sort in descending order\n"
      ],
      "metadata": {
        "id": "A8fccvymQvG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The voxel values in the images are raw. \n",
        "\n",
        "**dicom_HU** converts raw values into Houndsfeld units.\n",
        "This function takes as input all the slices of considered subject.\n",
        "The transformation is linear. \n",
        "\n",
        "Both the rescale intercept and rescale slope are stored in the DICOM header at the time of image acquisition.\n",
        "The final value is rescaled to HU.\n",
        "Windowing is then applied in order to adjust the grayscale level of the images.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wmbn9H5nb5Hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dicom_HU(scan):\n",
        "    image = np.stack([s.pixel_array*s.RescaleSlope+s.RescaleIntercept for s in scan],axis=2).astype(np.int16) #\n",
        "\n",
        "    img_min = 120 - 120 // 2 #minimum HU level\n",
        "    img_max = 120 + 120 // 2 #maximum HU level\n",
        "    window_image = image.copy()\n",
        "\n",
        "    window_image[window_image < img_min] = img_min #set img_min for all HU levels less than minimum HU level\n",
        "    window_image[window_image > img_max] = img_max #set img_max for all HU levels higher than maximum HU level\n",
        "    plt.figure(figsize=(20, 10))\n",
        "  \n",
        "    plt.style.use('grayscale') \n",
        "    plt.imshow(window_image[:,:,0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    return  np.array(window_image)"
      ],
      "metadata": {
        "id": "Lf6iW_JeQ4vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save as images in png format in a specific folder. A folder for each patient was created."
      ],
      "metadata": {
        "id": "99PJxyGNlKZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_slices=len(files)\n",
        "for i in range(1,num_slices):\n",
        "    scan=dicom_HU(slices[i-1:i])\n",
        "    plt.axis('off')\n",
        "    plt.savefig(f\"{images_path}\"+str(i)+\".png\", bbox_inches='tight',pad_inches = 0,dpi=300, quality=95) #dpi represents the resolution in dots per inch.\n",
        "                                                                                                        # A high value results in a high resolution image.\n",
        "                                                                                                    \n",
        "                                                                                                        #quality represents the image quality\n",
        "                                                                                                        #on a scale from 1 (worst) to 95 (best)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YSn_n5l-RD5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These operations must be repeated for all the subjects changing the paths."
      ],
      "metadata": {
        "id": "dKqoj5faonaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save **ROI.nrrd** files as png. masks"
      ],
      "metadata": {
        "id": "u-yjWLVTQrgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Drive"
      ],
      "metadata": {
        "id": "J9mVDuENQ3z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "5YFnPfdzSZ3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing SimpleITK to read .nrrd files "
      ],
      "metadata": {
        "id": "hkwpUx-0SjQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SimpleITK\n"
      ],
      "metadata": {
        "id": "O5lLb6vFSc6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries\n"
      ],
      "metadata": {
        "id": "vkFHKiorSiWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import SimpleITK as sitk\n",
        "import nibabel as nib\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "0TzT_To9RVhl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROI_path= glob.glob('/gdrive/MyDrive/ROI_out.nrrd') # Path of the .nrrd file\n"
      ],
      "metadata": {
        "id": "HDonMdltRZdq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the .nrrd files"
      ],
      "metadata": {
        "id": "7_8MnZ4zUhlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask_sitk  = sitk.ReadImage(ROI_path[0]) #read the masks\n",
        "sitk_shape=mask_sitk.GetSize() #get the masks size\n",
        "print(sitk_shape) # the first 2 dimensions are height and width , the last dimension represents the number of masks in the folder"
      ],
      "metadata": {
        "id": "ag8UFFF3UZA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save as masks in .png format in a  specific folder.\n",
        "A folder for each subject was created."
      ],
      "metadata": {
        "id": "HIYShr_lUek1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_slices=sitk_shape[2]\n",
        "for i in range(1,num_slices):\n",
        "    img=plt.imshow(sitk.GetArrayViewFromImage(mask_sitk)[i], cmap='gray')    \n",
        "    plt.axis('off')\n",
        "    plt.savefig(f\"{images_path}\"+str(i)+\".png\", bbox_inches='tight',pad_inches = 0,dpi=300, quality=95) #dpi represents the resolution in dots per inch.\n",
        "                                                                                                        # A high value results in a high resolution image.\n",
        "                                                                                                    \n",
        "                                                                                                        #quality represents the image quality\n",
        "                                                                                                        #on a scale from 1 (worst) to 95 (best)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "1iIVABUlRiOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These operations must be repeated for all the subjects changing the paths."
      ],
      "metadata": {
        "id": "RcW_Ba2jU9eq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21 folders were created, one for each subject. At the end of these steps, each folder contains two subfolders \"images\" and \"masks\" with the associated images and masks for each subject.\n",
        "Subjects's folders are splitted in TRAINING and VALIDATION folders.\n",
        "18 subjects are in TRAINING folder while 3 subjects are in VALIDATION one.\n",
        "7-fold cross validation was performed manually."
      ],
      "metadata": {
        "id": "dOySf4gqVE3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final folders creation"
      ],
      "metadata": {
        "id": "gYyYfujXcZWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the images and masks of each subject have been saved ,in the next part of the code four folders have been created: 'train_images' and 'train_masks' in which are all the images and the associated masks of the training set, and 'validation_images' and 'validation_masks' which contains the images and the associated masks of the validation set. This operation was necessary to perform Data Augumentation in a correct way, described in the later steps of the code.\n",
        "The images and the associated masks are charaterized by the same name."
      ],
      "metadata": {
        "id": "31_9eKTVWkEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Drive"
      ],
      "metadata": {
        "id": "DcODJfJ6XRBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "bIEhk1CxWo6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "gyJKqGKvXWUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from natsort import natsorted\n",
        "from google.colab.patches import cv2_imshow\n"
      ],
      "metadata": {
        "id": "oWgB7r57XZEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_path='/gdrive/MyDrive/TRAIN' #training path\n",
        "VALIDATION_path='/gdrive/MyDrive/VALIDATION'# validation path"
      ],
      "metadata": {
        "id": "8QS7UAElXd5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the images and masks of training set"
      ],
      "metadata": {
        "id": "_z3zLbzrZOyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_train_data(train_path):\n",
        "\n",
        "    train_x = (glob(f\"{TRAIN_path}/*/images/*.png\"))\n",
        "    train_y = (glob(f\"{TRAIN_path}/*/masks/*.png\"))\n",
        " \n",
        "    return train_x,train_y"
      ],
      "metadata": {
        "id": "blkI5cIyXhKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_x,train_y) = load_train_data(TRAIN_path)\n"
      ],
      "metadata": {
        "id": "FutlPVyqXmn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images and Masks of the training set are sorted naturally with natsorted function "
      ],
      "metadata": {
        "id": "A0N1jPpBZdTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x=natsorted(train_x)\n",
        "train_y=natsorted(train_y)\n",
        "print(len(train_x))   #train_x and train_y must have the same length , since they must contains the same number of files.\n",
        "print(len(train_y))"
      ],
      "metadata": {
        "id": "NU76pLQYZXiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the images and masks of validation set\n"
      ],
      "metadata": {
        "id": "DIcvIaESZQll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_val_data(val_path):\n",
        "    val_x= (glob(f\"{VALIDATION_path}/*/images/*.png\"))\n",
        "    val_y= (glob(f\"{VALIDATION_path}/*/masks/*.png\"))\n",
        "    return val_x,val_y"
      ],
      "metadata": {
        "id": "5OTQj2V7Xi5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(val_x,val_y) = load_val_data(VALIDATION_path)\n"
      ],
      "metadata": {
        "id": "vidWEbUAXpN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images and Masks of the validation set are sorted naturally with natsorted function.\n"
      ],
      "metadata": {
        "id": "rOS7UCKoaBWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_x=natsorted(val_x)\n",
        "val_y=natsorted(val_y)\n",
        "print(len(val_x))\n",
        "print(len(val_y))"
      ],
      "metadata": {
        "id": "oDEnAlgBZ_gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the 'train_images' and 'train_masks' folders"
      ],
      "metadata": {
        "id": "WR69pqhQo0Y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_train='/gdrive/MyDrive/train_images/images/' # final images path\n",
        "mask_path_train='/gdrive/MyDrive/train/train_masks/masks/' #final masks path"
      ],
      "metadata": {
        "id": "fPshTuOpafex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H = 256 #height \n",
        "W = 256 #width\n",
        "for idx, (x, y) in tqdm(enumerate(zip(train_x, train_y)), total=len(train_x)):\n",
        "        \"\"\" Extracting the folder name and image name for each subject \"\"\"\n",
        "        dir_name = x.split(\"/\")[-3]\n",
        "        name = dir_name + \"_\" + x.split(\"/\")[-1].split(\".\")[0] #extract the name of every subject's folder \n",
        "        \"\"\" Read the image and mask \"\"\"\n",
        "        x = cv2.imread(x, cv2.IMREAD_GRAYSCALE) #read the image\n",
        "        y = cv2.imread(y, cv2.IMREAD_GRAYSCALE) #read the mask\n",
        "        X = [x]\n",
        "        Y = [y]\n",
        "        idx = 0\n",
        "        for i, m in zip(X, Y):\n",
        "            i = cv2.resize(i, (W, H),interpolation = cv2.INTER_CUBIC)   #images are resized from 512x512 to 256x256 through cubic interpolation\n",
        "            m = cv2.resize(m, (W, H),interpolation = cv2.INTER_CUBIC)   #masks are resized from 512x512 to 256x256 through cubic interpolation\n",
        "\n",
        "            tmp_image_name = f\"{name}.png\"  #image and mask are saved with the same name \n",
        "            tmp_mask_name  = f\"{name}.png\" \n",
        "\n",
        "            image_path = os.path.join(image_path_train, tmp_image_name)\n",
        "            mask_path  = os.path.join(mask_path_train, tmp_mask_name)\n",
        "            print(tmp_image_name)\n",
        "\n",
        "            cv2.imwrite(image_path,i, [int(cv2.IMWRITE_PNG_COMPRESSION),0]) #save images in the folder\n",
        "            cv2.imwrite(mask_path, m, [int(cv2.IMWRITE_PNG_COMPRESSION),0]) #save masks in the folder\n",
        "                                                                            #with cv2.IMWRITE_PNG_COMPRESSION parameter the compression of the png image\n",
        "                                                                            #can be controlled. The value 0 pruduces the lowest compression\n",
        "            idx += 1"
      ],
      "metadata": {
        "id": "tSwt7yiTXsE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the 'validation_images' and 'validation_masks' folders"
      ],
      "metadata": {
        "id": "uq7rNv9ApAa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_validation='/gdrive/MyDrive/validation_images/images/' # final images path\n",
        "mask_path_validation='/gdrive/MyDrive/train/validation_masks/masks/' #final masks path"
      ],
      "metadata": {
        "id": "oFsVxit6pIXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H = 256 #height \n",
        "W = 256 #width\n",
        "for idx, (x, y) in tqdm(enumerate(zip(val_x, val_y)), total=len(val_x)):\n",
        "        \"\"\" Extracting the folder name and image name for each subject \"\"\"\n",
        "        dir_name = x.split(\"/\")[-3]\n",
        "        name = dir_name + \"_\" + x.split(\"/\")[-1].split(\".\")[0] #extract the name of every subject's folder \n",
        "        \"\"\" Read the image and mask \"\"\"\n",
        "        x = cv2.imread(x, cv2.IMREAD_GRAYSCALE) #read the image\n",
        "        y = cv2.imread(y, cv2.IMREAD_GRAYSCALE) #read the mask\n",
        "        X = [x]\n",
        "        Y = [y]\n",
        "        idx = 0\n",
        "        for i, m in zip(X, Y):\n",
        "            i = cv2.resize(i, (W, H),interpolation = cv2.INTER_CUBIC)   #images are resized from 512x512 to 256x256 through cubic interpolation\n",
        "            m = cv2.resize(m, (W, H),interpolation = cv2.INTER_CUBIC)   #masks are resized from 512x512 to 256x256 through cubic interpolation\n",
        "\n",
        "            tmp_image_name = f\"{name}.png\"  #image and mask are saved with the same name \n",
        "            tmp_mask_name  = f\"{name}.png\" \n",
        "\n",
        "            image_path = os.path.join(image_path_validation, tmp_image_name)\n",
        "            mask_path  = os.path.join(mask_path_validation, tmp_mask_name)\n",
        "            print(tmp_image_name)\n",
        "\n",
        "            cv2.imwrite(image_path,i, [int(cv2.IMWRITE_PNG_COMPRESSION),0]) #save images in the folder\n",
        "            cv2.imwrite(mask_path, m, [int(cv2.IMWRITE_PNG_COMPRESSION),0]) #save masks in the folder\n",
        "                                                                            #with cv2.IMWRITE_PNG_COMPRESSION parameter the compression of the png image\n",
        "                                                                            #can be controlled. The value 0 pruduces the lowest compression\n",
        "            idx += 1"
      ],
      "metadata": {
        "id": "-vyJvwtXX0sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Augmentation"
      ],
      "metadata": {
        "id": "cgDvMX7_psHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Drive"
      ],
      "metadata": {
        "id": "K6odPXqWqCrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "k7Y5Nb-Zp-zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries\n"
      ],
      "metadata": {
        "id": "H1u1aAq1qE8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from glob import glob\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "#from skimage.color import rgb2gray\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model, load_model, save_model\n",
        "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, add, concatenate,UpSampling2D,ZeroPadding2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "jsVI_qZLqKdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_path = \"/gdrive/MyDrive/train_images\" # training images path\n",
        "train_mask_path = \"/gdrive/MyDrive/train_masks\" # training masks path\n",
        "\n",
        "val_img_path = \"/gdrive/MyDrive/validation_images\" # validation images path\n",
        "val_mask_path = \"/gdrive/MyDrive/validation_masks\" # validation masks path"
      ],
      "metadata": {
        "id": "K2y568h1qX5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation is applied simultaneously to trainining images and masks"
      ],
      "metadata": {
        "id": "yaZnhwhYxMrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_data_gen_args_train = dict(rescale=1./255,   #rescale the images\n",
        "                     rotation_range=90,          #random rotation \n",
        "                     brightness_range=[0.3,1.5], # random change of brightness\n",
        "                     width_shift_range=0.3,      # random width shifting\n",
        "                     height_shift_range=0.3,     #random height shifting\n",
        "                     shear_range=0.5,            #shear transformation\n",
        "                     horizontal_flip=True,       #horizontal flip\n",
        "                     vertical_flip=True,         # vertical flip\n",
        "                     fill_mode='reflect')        # fill mode\n",
        "\n",
        "mask_data_gen_args_train = dict(\n",
        "                     rotation_range=90,          #random rotation \n",
        "                     brightness_range=[0.3,1.5], # random change of brightness\n",
        "                     width_shift_range=0.3,      # random width shifting\n",
        "                     height_shift_range=0.3,     #random height shifting\n",
        "                     shear_range=0.5,            #shear transformation\n",
        "                     horizontal_flip=True,       #horizontal flip\n",
        "                     vertical_flip=True,         # vertical flip\n",
        "                     fill_mode='reflect',       # fill mode\n",
        "\n",
        "                     preprocessing_function = lambda x: np.where(x>0, 1, 0).astype(x.dtype) #Binarize the masks.\n",
        "                     \n",
        "                     )  \n",
        "\n",
        "image_data_generator_train = ImageDataGenerator(**img_data_gen_args_train)\n",
        "mask_data_generator_train = ImageDataGenerator(**mask_data_gen_args_train)"
      ],
      "metadata": {
        "id": "qlCteBicqmU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation is not applied to validation images and masks.\n",
        "ImageDataGenerator is used to rescale the images and binarize the masks only."
      ],
      "metadata": {
        "id": "Jz6dwulgxVtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_data_gen_args_val = dict(rescale=1./255) #rescale the images\n",
        "\n",
        "mask_data_gen_args_val = dict(\n",
        "                     preprocessing_function = lambda x: np.where(x>0, 1, 0).astype(x.dtype)\n",
        "                     \n",
        "                     ) #Binarize the masks. \n",
        "\n",
        "image_data_generator_val = ImageDataGenerator(**img_data_gen_args_val)\n",
        "mask_data_generator_val = ImageDataGenerator(**mask_data_gen_args_val)"
      ],
      "metadata": {
        "id": "fsHp5ybeq_NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ImageDataGenerator produces 2 generators,one for training and one for validation with the images and associated masks.\n",
        "These generators will be the input of the model."
      ],
      "metadata": {
        "id": "uKPgTQT80F3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed=42\n",
        "batch_size=16\n",
        "image_generator = image_data_generator_train.flow_from_directory(train_img_path, #path\n",
        "                                                           seed=seed, # must be the same to ensure that images and masks are edited in the same way\n",
        "                                                           batch_size=batch_size,\n",
        "                                                           color_mode = 'grayscale', #Read images in grayscale\n",
        "                                                           target_size=(256,256), #specify the height and the width\n",
        "                                                           class_mode=None)  #Very important to set this otherwise it returns multiple numpy arrays \n",
        "                                                                            \n",
        "\n",
        "mask_generator = mask_data_generator_train.flow_from_directory(train_mask_path, \n",
        "                                                         seed=seed, \n",
        "                                                         batch_size=batch_size,\n",
        "                                                         color_mode = 'grayscale',\n",
        "                                                         target_size=(256,256)  , \n",
        "                                                         class_mode=None)\n",
        "\n",
        "\n",
        "valid_img_generator = image_data_generator_val.flow_from_directory(val_img_path, \n",
        "                                                               seed=seed, \n",
        "                                                               batch_size=batch_size, \n",
        "                                                               color_mode = 'grayscale', \n",
        "                                                               target_size=(256,256),\n",
        "                                                               class_mode=None) \n",
        "\n",
        "\n",
        "valid_mask_generator = mask_data_generator_val.flow_from_directory(val_mask_path, \n",
        "                                                               seed=seed, \n",
        "                                                               batch_size=batch_size, \n",
        "                                                               target_size=(256,256),\n",
        "                                                               \n",
        "                                                               color_mode = 'grayscale',  \n",
        "                                                               class_mode=None)  \n",
        "\n",
        "\n",
        "train_generator = zip(image_generator, mask_generator)\n",
        "val_generator = zip(valid_img_generator, valid_mask_generator)"
      ],
      "metadata": {
        "id": "LuqogoIwrVSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show some example of augmented images and check if they are associated in correct way to the masks"
      ],
      "metadata": {
        "id": "73XdsLsK0i5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x, y = train_generator.__next__()\n",
        "\n",
        "for i in range(0,8):\n",
        "    image = x[i,:,:,0]\n",
        "    mask= y[i,:,:,0]\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oG81217DraQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if images and masks are rescaled. \n",
        "Values must be between 0 and 1 for images and 0 or 1 for masks"
      ],
      "metadata": {
        "id": "DTF07IHW1F43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.max())\n",
        "print(y.max())"
      ],
      "metadata": {
        "id": "ICqWYfBgrc1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "u0Uu6kqV2m0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the input shape of the model"
      ],
      "metadata": {
        "id": "JxutoNnl3UWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = x.shape[1]\n",
        "IMG_WIDTH  = x.shape[2]\n",
        "IMG_CHANNELS = x.shape[3]\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "print(input_shape)"
      ],
      "metadata": {
        "id": "2_BQXax23SO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unet-based Architecture"
      ],
      "metadata": {
        "id": "lS-rEBOi3beV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(input_shape)\n",
        "#Contraction path\n",
        "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
        "c1= tf.keras.layers.BatchNormalization()(c1)\n",
        "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "c1= tf.keras.layers.BatchNormalization()(c1)\n",
        "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "c2= tf.keras.layers.BatchNormalization()(c2)\n",
        "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "c2= tf.keras.layers.BatchNormalization()(c2)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        " \n",
        "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "c3= tf.keras.layers.BatchNormalization()(c3)\n",
        "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
        "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "c3= tf.keras.layers.BatchNormalization()(c3)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        " \n",
        "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "c4= tf.keras.layers.BatchNormalization()(c4)\n",
        "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
        "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "c4= tf.keras.layers.BatchNormalization()(c4)\n",
        "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        " \n",
        "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "c5= tf.keras.layers.BatchNormalization()(c5)\n",
        "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
        "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "c5= tf.keras.layers.BatchNormalization()(c5)\n",
        "#Expansive path \n",
        "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        " \n",
        "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        " \n",
        "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        " \n",
        "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        " \n",
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)"
      ],
      "metadata": {
        "id": "7QVvEAC0sCIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "qdKklGHusEWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the steps per epoch for training and validation required to train the model"
      ],
      "metadata": {
        "id": "r9T_yeLO2jvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_imgs = len(os.listdir(\"/gdrive/MyDrive/train_images/images\")) #images path\n",
        "num_val_images = len(os.listdir(\"/gdrive/MyDrive/val_images/images\"))   #masks path\n",
        "\n",
        "steps_per_epoch = num_train_imgs//batch_size\n",
        "val_steps_per_epoch = num_val_images//batch_size\n"
      ],
      "metadata": {
        "id": "NCnavx46ryDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the model metrcis and losses.\n",
        "Dice Loss, IoU Loss, Tversky Loss, Focal Loss have been tested"
      ],
      "metadata": {
        "id": "qjeCiyk34Rv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=0.0001):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "\n",
        "    return ((2. * intersection + smooth) / (K.sum(y_true_f) +\n",
        "            K.sum(y_pred_f) + smooth))\n",
        "\n",
        "\n",
        "def dice_coefficient_loss(y_true, y_pred):\n",
        "    return 1.0-dice_coefficient(y_true, y_pred)\n",
        "\n",
        "\n",
        "def iou_loss(y_true, y_pred):\n",
        "    return 1-iou(y_true, y_pred)\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred))\n",
        "    sum_ = K.sum(K.square(y_true)) + K.sum(K.square(y_pred))\n",
        "    jac = (intersection) / (sum_ - intersection)\n",
        "    return jac\n",
        "\n",
        "def tversky(y_true, y_pred):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
        "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
        "\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    return 1 - tversky(y_true,y_pred)\n"
      ],
      "metadata": {
        "id": "KQOYs3R0sHRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Learning Rate and Optimizer"
      ],
      "metadata": {
        "id": "UoA9h-ph5csb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 5e-5\n",
        "optim = tf.keras.optimizers.Adam(LR) #Adaptive Moment Estimation Optimizer"
      ],
      "metadata": {
        "id": "E2DVmo2CsJYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Metrics used"
      ],
      "metadata": {
        "id": "nAkXeJUJ5uaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [iou, dice_coefficient, 'binary_accuracy']\n"
      ],
      "metadata": {
        "id": "4vjvTbkFsLIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model"
      ],
      "metadata": {
        "id": "FZRwY7J-5yEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optim, loss=dice_coefficient_loss, metrics=metrics)\n"
      ],
      "metadata": {
        "id": "66jJCnt8sNLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add callback to save the best model "
      ],
      "metadata": {
        "id": "OafE0_t16Qnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/gdrive/MyDrive/chk/',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_dice_coefficient',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "rCi4vh1c6OYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "prwjBXAU7Mdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_generator,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          callbacks=model_checkpoint_callback,\n",
        "          validation_data=val_generator,\n",
        "          validation_steps=val_steps_per_epoch)"
      ],
      "metadata": {
        "id": "IvFm8H7asPCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model in .h5 format"
      ],
      "metadata": {
        "id": "lNEMYj0K6cq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path='/gdrive/MyDrive/model.h5'"
      ],
      "metadata": {
        "id": "BuYv7R0T6fr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(model_path)\n"
      ],
      "metadata": {
        "id": "WLp6SvwwsRo3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
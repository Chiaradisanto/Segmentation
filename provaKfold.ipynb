{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "provaKfold.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9UnCzg1eOWp5LZP9Q/9gS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chiaradisanto/Segmentation/blob/main/provaKfold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvh0gYIzFyp9",
        "outputId": "0a1286ad-d7b9-4678-80bf-63175f909c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from natsort import natsorted\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "BY6jShd3GkKq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "u0K00UFxHUtR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From: https://github.com/zhixuhao/unet/blob/master/data.py\n",
        "def train_generator(data_frame, batch_size, train_path, aug_dict,\n",
        "        image_color_mode=\"grayscale\",\n",
        "        mask_color_mode=\"grayscale\",\n",
        "        save_to_dir=None,\n",
        "        target_size=(512,512),\n",
        "        seed=42):\n",
        "    '''\n",
        "    can generate image and mask at the same time use the same seed for\n",
        "    image_datagen and mask_datagen to ensure the transformation for image\n",
        "    and mask is the same if you want to visualize the results of generator,\n",
        "    set save_to_dir = \"your path\"\n",
        "    '''\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "    \n",
        "    image_generator = image_datagen.flow_from_dataframe(\n",
        "        data_frame,\n",
        "        directory = train_path,\n",
        "        x_col = \"images\",\n",
        "        class_mode = None,\n",
        "        color_mode = image_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "\n",
        "        seed = seed)\n",
        "\n",
        "    mask_generator = mask_datagen.flow_from_dataframe(\n",
        "        data_frame,\n",
        "        directory = train_path,\n",
        "        x_col = \"masks\",\n",
        "        class_mode = None,\n",
        "        color_mode = mask_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "\n",
        "        seed = seed)\n",
        "\n",
        "    train_gen = zip(image_generator, mask_generator)\n",
        "    \n",
        "    for (img, mask) in train_gen:\n",
        "        img, mask = adjust_data(img, mask)\n",
        "        yield (img,mask)\n",
        "\n",
        "def adjust_data(img,mask):\n",
        "    img = img / 255.\n",
        "    mask = mask / 255.\n",
        "   \n",
        "    \n",
        "    return (img, mask)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pzaET6J9HNSO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_x = glob.glob(os.path.join('/gdrive/MyDrive/TESI/output/train/train_images/images', \"*.png\"))\n",
        "train_y = glob.glob(os.path.join('/gdrive/MyDrive/TESI/output/train/train_masks/masks', \"*.png\"))"
      ],
      "metadata": {
        "id": "lkZ59G1bGmFK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x=natsorted(train_x)\n",
        "train_y=natsorted(train_y)"
      ],
      "metadata": {
        "id": "USM862b_JHww"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=0.0001):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "\n",
        "    return ((2. * intersection + smooth) / (K.sum(y_true_f) +\n",
        "            K.sum(y_pred_f) + smooth))\n",
        "\n",
        "\n",
        "def dice_coefficient_loss(y_true, y_pred):\n",
        "    return 1.0-dice_coefficient(y_true, y_pred)\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred))\n",
        "    sum_ = K.sum(K.square(y_true)) + K.sum(K.square(y_pred))\n",
        "    jac = (intersection) / (sum_ - intersection)\n",
        "    return jac\n",
        "def iou_loss(y_true, y_pred):\n",
        "    return 1.0 -iou(y_true, y_pred)"
      ],
      "metadata": {
        "id": "zuww_y8eIkZR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n"
      ],
      "metadata": {
        "id": "NiWsYYB4JMVJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "df = pandas.DataFrame(data={\"images\": train_x, 'masks' : train_y})\n",
        "\n",
        "kf = KFold(n_splits = 5, shuffle=False)"
      ],
      "metadata": {
        "id": "bA-jzJNBIpbm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, (train_index, test_index) in enumerate(kf.split(df)):\n",
        "    train_data_frame = df.iloc[train_index]\n",
        "    test_data_frame = df.iloc[test_index]"
      ],
      "metadata": {
        "id": "JouzgipyJPwQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=8"
      ],
      "metadata": {
        "id": "wiVThm0vJZFJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_shape = (512, 512, 1)\n",
        "print(input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgAnZeXGJtOA",
        "outputId": "701065d5-04c1-49ef-f5e2-6ee220c7791c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 512, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "hBxzKafVJvSy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_data_frame))\n",
        "print(len(train_data_frame))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo5v9tG-JxKv",
        "outputId": "715e3790-345b-4757-8697-ef0e296c7de6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "652\n",
            "2608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(input_shape)\n",
        "#Contraction path\n",
        "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
        "c1= tf.keras.layers.BatchNormalization()(c1)\n",
        "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "c1= tf.keras.layers.BatchNormalization()(c1)\n",
        "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "c2= tf.keras.layers.BatchNormalization()(c2)\n",
        "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "c2= tf.keras.layers.BatchNormalization()(c2)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        " \n",
        "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "c3= tf.keras.layers.BatchNormalization()(c3)\n",
        "\n",
        "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
        "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "c3= tf.keras.layers.BatchNormalization()(c3)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        " \n",
        "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "c4= tf.keras.layers.BatchNormalization()(c4)\n",
        "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
        "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "c4= tf.keras.layers.BatchNormalization()(c4)\n",
        "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        " \n",
        "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "c5= tf.keras.layers.BatchNormalization()(c5)\n",
        "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
        "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "c5= tf.keras.layers.BatchNormalization()(c5)\n",
        "#Expansive path \n",
        "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        " \n",
        "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        " \n",
        "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        " \n",
        "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        " \n",
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)"
      ],
      "metadata": {
        "id": "_7C1WM9GJ3yQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biSwM_3CKBlq",
        "outputId": "f428aa62-96bb-4d41-ed8d-eef7658e4166"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512, 512, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 512, 512, 16  160         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 512, 512, 16  64         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 512, 512, 16  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 512, 512, 16  2320        ['dropout[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 512, 512, 16  64         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 256, 256, 16  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 256, 256, 32  4640        ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 256, 256, 32  128        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 256, 256, 32  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 256, 256, 32  9248        ['dropout_1[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 256, 256, 32  128        ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32  0          ['batch_normalization_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 128, 128, 64  18496       ['max_pooling2d_1[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128, 128, 64  256        ['conv2d_4[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 128, 128, 64  0           ['batch_normalization_4[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 128, 128, 64  36928       ['dropout_2[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 128, 128, 64  256        ['conv2d_5[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 64, 64, 128)  73856       ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 64, 64, 128)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 64, 64, 128)  147584      ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 128)  0          ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 32, 32, 256)  295168      ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 32, 32, 256)  0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 32, 32, 256)  590080      ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 64, 64, 128)  131200     ['batch_normalization_9[0][0]']  \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64, 64, 256)  0           ['conv2d_transpose[0][0]',       \n",
            "                                                                  'batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 64, 64, 128)  295040      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 64, 64, 128)  0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 64, 64, 128)  147584      ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 64  32832      ['conv2d_11[0][0]']              \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128, 128, 12  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                8)                                'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 128, 128, 64  73792       ['concatenate_1[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 128, 128, 64  0           ['conv2d_12[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 128, 128, 64  36928       ['dropout_6[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 32  8224       ['conv2d_13[0][0]']              \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 256, 256, 64  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                )                                 'batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 256, 256, 32  18464       ['concatenate_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 256, 256, 32  0           ['conv2d_14[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 256, 256, 32  9248        ['dropout_7[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 512, 512, 16  2064       ['conv2d_15[0][0]']              \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 512, 512, 32  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                )                                 'batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 512, 512, 16  4624        ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 512, 512, 16  0           ['conv2d_16[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 512, 512, 16  2320        ['dropout_8[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 512, 512, 1)  17          ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,944,785\n",
            "Trainable params: 1,942,801\n",
            "Non-trainable params: 1,984\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.00001\n",
        "optim = tf.keras.optimizers.Adam(LR)"
      ],
      "metadata": {
        "id": "gwnG59aAKDXl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "LFMQo0esKHb6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model, load_model, save_model\n"
      ],
      "metadata": {
        "id": "y3XmjO9IKJM5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=8\n",
        "train_generator_args = dict(rotation_range=0.2,\n",
        "                            width_shift_range=0.05,\n",
        "                            height_shift_range=0.05,\n",
        "                            shear_range=0.05,\n",
        "                            zoom_range=0.05,\n",
        "                            horizontal_flip=True,\n",
        "                            fill_mode='nearest')\n",
        "\n",
        "histories = []\n",
        "losses = []\n",
        "accuracies = []\n",
        "dicecoefs = []\n",
        "ious = []\n",
        "\n",
        "for k, (train_index, test_index) in enumerate(kf.split(df)):\n",
        "    train_data_frame = df.iloc[train_index]\n",
        "    test_data_frame = df.iloc[test_index]\n",
        "    \n",
        "    train_gen = train_generator(train_data_frame, BATCH_SIZE,\n",
        "                                None,\n",
        "                                train_generator_args,\n",
        "                                target_size=(512,512))\n",
        "\n",
        "    test_gener = train_generator(test_data_frame, BATCH_SIZE,\n",
        "                                None,\n",
        "                                train_generator_args,\n",
        "                                target_size=(512,512))\n",
        "\n",
        "    model.compile(optimizer=optim, loss=iou_loss, \\\n",
        "                      metrics=[iou, dice_coefficient, 'binary_accuracy'])\n",
        "  # model.summary()\n",
        "\n",
        " \n",
        "    history = model.fit(train_gen,\n",
        "                                  steps_per_epoch=len(train_data_frame) / BATCH_SIZE, \n",
        "                                  epochs=32, \n",
        "                             \n",
        "                                  validation_data = test_gener,\n",
        "                                  validation_steps=len(test_data_frame) / BATCH_SIZE)\n",
        "    model=model.save(str(k+1) + '_kfoldUNET.hdf5')\n",
        "    \n",
        "    model = load_model(str(k+1) + '_kfoldUNET.hdf5', custom_objects={'dice_coef_loss': dice_coefficient_loss, 'iou': iou, 'dice_coefficient': dice_coefficient,'iou_loss':iou_loss})\n",
        "    \n",
        "    test_gen = train_generator(test_data_frame, BATCH_SIZE,\n",
        "                                None,\n",
        "                                train_generator_args,\n",
        "                                target_size=(512,512))\n",
        "    results = model.evaluate(test_gen, steps=len(test_data_frame))\n",
        "    results = dict(zip(model.metrics_names,results))\n",
        "    \n",
        "    histories.append(history)\n",
        "    accuracies.append(results['binary_accuracy'])\n",
        "    losses.append(results['loss'])\n",
        "    dicecoefs.append(results['dice_coefficient'])\n",
        "    ious.append(results['iou'])\n",
        "\n"
      ],
      "metadata": {
        "id": "X265ef2xKagL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a667a15c-90de-4638-837e-f66f12182a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2608 validated image filenames.\n",
            "Found 2608 validated image filenames.\n",
            "Epoch 1/32\n",
            "326/326 [==============================] - ETA: 0s - loss: 0.9126 - iou: 0.0874 - dice_coefficient: 0.0743 - binary_accuracy: 0.8584Found 652 validated image filenames.\n",
            "Found 652 validated image filenames.\n",
            "326/326 [==============================] - 178s 521ms/step - loss: 0.9126 - iou: 0.0874 - dice_coefficient: 0.0743 - binary_accuracy: 0.8584 - val_loss: 0.9924 - val_iou: 0.0075 - val_dice_coefficient: 0.0125 - val_binary_accuracy: 0.9663\n",
            "Epoch 2/32\n",
            "326/326 [==============================] - 164s 505ms/step - loss: 0.7363 - iou: 0.2637 - dice_coefficient: 0.2578 - binary_accuracy: 0.9746 - val_loss: 0.8259 - val_iou: 0.1739 - val_dice_coefficient: 0.2308 - val_binary_accuracy: 0.9656\n",
            "Epoch 3/32\n",
            "326/326 [==============================] - 164s 503ms/step - loss: 0.6313 - iou: 0.3687 - dice_coefficient: 0.4143 - binary_accuracy: 0.9770 - val_loss: 0.7978 - val_iou: 0.2023 - val_dice_coefficient: 0.2838 - val_binary_accuracy: 0.9661\n",
            "Epoch 4/32\n",
            "326/326 [==============================] - 163s 502ms/step - loss: 0.5759 - iou: 0.4241 - dice_coefficient: 0.4779 - binary_accuracy: 0.9802 - val_loss: 0.7870 - val_iou: 0.2127 - val_dice_coefficient: 0.3006 - val_binary_accuracy: 0.9673\n",
            "Epoch 5/32\n",
            "326/326 [==============================] - 163s 502ms/step - loss: 0.5593 - iou: 0.4407 - dice_coefficient: 0.4889 - binary_accuracy: 0.9813 - val_loss: 0.8151 - val_iou: 0.1857 - val_dice_coefficient: 0.2703 - val_binary_accuracy: 0.9673\n",
            "Epoch 6/32\n",
            "326/326 [==============================] - 163s 501ms/step - loss: 0.5419 - iou: 0.4581 - dice_coefficient: 0.5011 - binary_accuracy: 0.9822 - val_loss: 0.8060 - val_iou: 0.1928 - val_dice_coefficient: 0.2816 - val_binary_accuracy: 0.9678\n",
            "Epoch 7/32\n",
            "326/326 [==============================] - 164s 505ms/step - loss: 0.5189 - iou: 0.4811 - dice_coefficient: 0.5211 - binary_accuracy: 0.9830 - val_loss: 0.7827 - val_iou: 0.2179 - val_dice_coefficient: 0.3136 - val_binary_accuracy: 0.9683\n",
            "Epoch 8/32\n",
            "326/326 [==============================] - 165s 506ms/step - loss: 0.5095 - iou: 0.4905 - dice_coefficient: 0.5278 - binary_accuracy: 0.9835 - val_loss: 0.7302 - val_iou: 0.2702 - val_dice_coefficient: 0.3704 - val_binary_accuracy: 0.9688\n",
            "Epoch 9/32\n",
            "326/326 [==============================] - 168s 516ms/step - loss: 0.5075 - iou: 0.4925 - dice_coefficient: 0.5291 - binary_accuracy: 0.9839 - val_loss: 0.8122 - val_iou: 0.1875 - val_dice_coefficient: 0.2771 - val_binary_accuracy: 0.9684\n",
            "Epoch 10/32\n",
            "326/326 [==============================] - 164s 502ms/step - loss: 0.4929 - iou: 0.5071 - dice_coefficient: 0.5413 - binary_accuracy: 0.9844 - val_loss: 0.6681 - val_iou: 0.3317 - val_dice_coefficient: 0.4339 - val_binary_accuracy: 0.9717\n",
            "Epoch 11/32\n",
            "326/326 [==============================] - 164s 503ms/step - loss: 0.4867 - iou: 0.5133 - dice_coefficient: 0.5466 - binary_accuracy: 0.9846 - val_loss: 0.6819 - val_iou: 0.3175 - val_dice_coefficient: 0.4199 - val_binary_accuracy: 0.9715\n",
            "Epoch 12/32\n",
            "326/326 [==============================] - 165s 507ms/step - loss: 0.4786 - iou: 0.5214 - dice_coefficient: 0.5530 - binary_accuracy: 0.9849 - val_loss: 0.6911 - val_iou: 0.3071 - val_dice_coefficient: 0.4124 - val_binary_accuracy: 0.9715\n",
            "Epoch 13/32\n",
            "326/326 [==============================] - 163s 501ms/step - loss: 0.4697 - iou: 0.5303 - dice_coefficient: 0.5622 - binary_accuracy: 0.9852 - val_loss: 0.6366 - val_iou: 0.3634 - val_dice_coefficient: 0.4656 - val_binary_accuracy: 0.9731\n",
            "Epoch 14/32\n",
            "326/326 [==============================] - 163s 501ms/step - loss: 0.4652 - iou: 0.5348 - dice_coefficient: 0.5657 - binary_accuracy: 0.9854 - val_loss: 0.6569 - val_iou: 0.3435 - val_dice_coefficient: 0.4507 - val_binary_accuracy: 0.9716\n",
            "Epoch 15/32\n",
            "326/326 [==============================] - 164s 505ms/step - loss: 0.4578 - iou: 0.5422 - dice_coefficient: 0.5750 - binary_accuracy: 0.9857 - val_loss: 0.6520 - val_iou: 0.3481 - val_dice_coefficient: 0.4550 - val_binary_accuracy: 0.9729\n",
            "Epoch 16/32\n",
            "326/326 [==============================] - 164s 502ms/step - loss: 0.4574 - iou: 0.5426 - dice_coefficient: 0.5729 - binary_accuracy: 0.9859 - val_loss: 0.6628 - val_iou: 0.3373 - val_dice_coefficient: 0.4446 - val_binary_accuracy: 0.9720\n",
            "Epoch 17/32\n",
            "326/326 [==============================] - 163s 502ms/step - loss: 0.4443 - iou: 0.5557 - dice_coefficient: 0.5869 - binary_accuracy: 0.9862 - val_loss: 0.6555 - val_iou: 0.3446 - val_dice_coefficient: 0.4487 - val_binary_accuracy: 0.9732\n",
            "Epoch 18/32\n",
            "326/326 [==============================] - 163s 500ms/step - loss: 0.4440 - iou: 0.5560 - dice_coefficient: 0.5845 - binary_accuracy: 0.9863 - val_loss: 0.6060 - val_iou: 0.3944 - val_dice_coefficient: 0.4953 - val_binary_accuracy: 0.9739\n",
            "Epoch 19/32\n",
            "326/326 [==============================] - 163s 500ms/step - loss: 0.4311 - iou: 0.5689 - dice_coefficient: 0.5973 - binary_accuracy: 0.9866 - val_loss: 0.6604 - val_iou: 0.3383 - val_dice_coefficient: 0.4418 - val_binary_accuracy: 0.9722\n",
            "Epoch 20/32\n",
            "326/326 [==============================] - 163s 501ms/step - loss: 0.4374 - iou: 0.5626 - dice_coefficient: 0.5912 - binary_accuracy: 0.9866 - val_loss: 0.6084 - val_iou: 0.3919 - val_dice_coefficient: 0.4968 - val_binary_accuracy: 0.9743\n",
            "Epoch 21/32\n",
            "326/326 [==============================] - 163s 501ms/step - loss: 0.4202 - iou: 0.5798 - dice_coefficient: 0.6083 - binary_accuracy: 0.9869 - val_loss: 0.6307 - val_iou: 0.3700 - val_dice_coefficient: 0.4712 - val_binary_accuracy: 0.9741\n",
            "Epoch 22/32\n",
            "326/326 [==============================] - 163s 501ms/step - loss: 0.4317 - iou: 0.5683 - dice_coefficient: 0.5958 - binary_accuracy: 0.9869 - val_loss: 0.5916 - val_iou: 0.4088 - val_dice_coefficient: 0.5120 - val_binary_accuracy: 0.9742\n",
            "Epoch 23/32\n",
            "326/326 [==============================] - 163s 499ms/step - loss: 0.4178 - iou: 0.5822 - dice_coefficient: 0.6100 - binary_accuracy: 0.9871 - val_loss: 0.6635 - val_iou: 0.3367 - val_dice_coefficient: 0.4449 - val_binary_accuracy: 0.9725\n",
            "Epoch 24/32\n",
            "230/326 [====================>.........] - ETA: 39s - loss: 0.4145 - iou: 0.5855 - dice_coefficient: 0.6136 - binary_accuracy: 0.9871"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FLuJOAn6tODy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Ln-xA53i8vUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracies : ', accuracies)\n",
        "print('losses : ', losses)\n",
        "print('dicecoefs : ', dicecoefs)\n",
        "print('ious : ', ious)\n",
        "\n",
        "print('-----------------------------------------------------------------------------')\n",
        "print('-----------------------------------------------------------------------------')\n",
        "\n",
        "print('average accuracy : ', np.mean(np.array(accuracies)))\n",
        "print('average loss : ', np.mean(np.array(losses)))\n",
        "print('average dicecoefs : ', np.mean(np.array(dicecoefs)))\n",
        "print('average ious : ', np.mean(np.array(ious)))\n",
        "print()\n",
        "\n",
        "print('standard deviation of accuracy : ', np.std(np.array(accuracies)))\n",
        "print('standard deviation of loss : ', np.std(np.array(losses)))\n",
        "print('standard deviation of dicecoefs : ', np.std(np.array(dicecoefs)))\n",
        "print('standard deviation of ious : ', np.std(np.array(ious)))\n"
      ],
      "metadata": {
        "id": "qab0wBsL8kh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "OUyRVg1j9mba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "for h, history in enumerate(histories):\n",
        "\n",
        "    keys = history.history.keys()\n",
        "    fig, axs = plt.subplots(1, len(keys)//2, figsize = (25, 5))\n",
        "    fig.suptitle('No. ' + str(h+1) + ' Fold Results', fontsize=30)\n",
        "\n",
        "    for k, key in enumerate(list(keys)[:len(keys)//2]):\n",
        "        training = history.history[key]\n",
        "        validation = history.history['val_' + key]\n",
        "\n",
        "        epoch_count = range(1, len(training) + 1)\n",
        "\n",
        "        axs[k].plot(epoch_count, training, 'r--')\n",
        "        axs[k].plot(epoch_count, validation, 'b-')\n",
        "        axs[k].legend(['Training ' + key, 'Validation ' + key])\n",
        "                \n",
        "    with open(str(h+1) + '_lungs_trainHistoryDict', 'wb') as file_pi:\n",
        "        pickle.dump(history.history, file_pi)"
      ],
      "metadata": {
        "id": "kDeLc2XU61i5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('1_KfoldUNET.hdf5.hdf5', custom_objects={'dice_coefficient_loss': dice_coefficient_loss, 'iou': iou, 'dice_coef': dice_coefficient,'iou_loss':iou_loss})"
      ],
      "metadata": {
        "id": "qYACbRO989yn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}